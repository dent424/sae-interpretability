# -*- coding: utf-8 -*-
"""Fixed Path New Interpretability Notebook - Mexican National e32 k32 lr0.0003

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1acLDCnv0siogX5SuAzU2BiqYLydqyQh_

#Fixed Path Interpretability Notebook

## Chapter 0: Import Packages, Mount Drive, Examine Data
This should be done prior to all other steps

** NOTE**
1. Because we are installing transformer-lens to the VM and it has some dependency issues, you will first need to run 0.1 once, restart and then run it again. You should only need to do this the first time you connect to colab
2. You will want to use a T4 (or if you want to splurge an L4) runtime to make this work. Otherwise it will take forwever to run these functions
3. Note that if you are using a shared file, you will want to put a shortcut to that file in your own drive and point there instead of to the shared version (unless you are the originator of the share file)
4. In step 1.1 you will be asked for an API key - that key is for loading the SAE and it is available in the text comments right before the cell that asks for it.

## 0.1: Load Packages
"""

# Install required packages
!pip install transformer-lens
!pip install wandb
!pip install h5py

##########################
#IMPORTS
##########################

# File I/O and system operations
import os
import sys
import shutil
import h5py
from google.colab import drive
import glob
from collections import Counter
import requests
import importlib
import csv
import io


# Data manipulation and numerical computing
import numpy as np
import math
import pandas as pd
from collections import defaultdict, Counter
import re

# Visualization
import matplotlib.pyplot as plt
from IPython.display import HTML, display
import matplotlib.colors as mcolors

# Deep learning frameworks
import torch
from torch import nn

# Model libraries and tokenization
from transformers import AutoTokenizer
from transformer_lens import HookedTransformer

# Experiment tracking
import wandb
from tqdm.auto import tqdm

# Mount Google Drive
print("üìÇ Mounting Google Drive...")
drive.mount('/content/drive')

#DRIVE PATHS
#PATH FOR SAE ACTIVATIONS AND METADATA
METADATA_CSV_PATH = "/content/drive/My Drive/WORK/Bottom Up Psychometric Coding/Yelp Data/mexican_national_metadata.npz"
H5_SAE_PATH = "/content/drive/My Drive/WORK/Bottom Up Psychometric Coding/Yelp Data/mexican_national_sae_features_e32_k32_lr0_0003-final.h5"  # UPDATE THIS
MODEL_PATH = "/content/drive/My Drive/WORK/Bottom Up Psychometric Coding/sae_e32_k32_lr0.0003-final.pt"

#LOCAL PATHS - STORE FILES LOCALLY TO PREVENT HITTING THE DRIVE ACCESS QUOTAS
LOCAL_H5_SAE_PATH = "/content/sae_features.h5"
LOCAL_METADATA_PATH = "/content/metadata.npz"
LOCAL_MODEL_PATH = "/content/sae_e32_k32_lr0.0003-final.pt"


# Initialize tokenizer
print("Loading tokenizer...")
tok = AutoTokenizer.from_pretrained("gpt2")

"""## 0.2: Load Data
* SAE Activations are loaded
* Metadata is loaded
* Metadata is stored in memory in a df called "metadata_df"
"""

# Copy files to local storage
print("üìÇ Copying files to local storage...")

# Copy SAE features
print(f"Copying SAE features...")
shutil.copy(H5_SAE_PATH, LOCAL_H5_SAE_PATH)
print(f"‚úÖ SAE features copied to: {LOCAL_H5_SAE_PATH}")

# Copy Metadata
print(f"\nCopying Metadata...")
shutil.copy(METADATA_CSV_PATH, LOCAL_METADATA_PATH)
print(f"‚úÖ METADATA copied to: {LOCAL_METADATA_PATH}")

# Verify file sizes
print("\nüìä File sizes:")
sae_size = os.path.getsize(LOCAL_H5_SAE_PATH) / 1e9
meta_size = os.path.getsize(LOCAL_METADATA_PATH) / 1e9
print(f"  SAE features: {sae_size:.2f} GB")
print(f"  Metadata activations: {meta_size:.2f} GB")

# Load metadata into DataFrame
print("\nüìä Loading metadata into DataFrame...")
data = np.load(LOCAL_METADATA_PATH, allow_pickle=True)

# Create DataFrame from the individual arrays
metadata_df = pd.DataFrame({
    'review_id': data['review_ids'],
    'full_text': data['texts'],  # Note: renamed from 'texts' to match your original code
    'stars': data['stars'],
    'useful': data['useful'],
    'user_id': data['user_ids'],
    'business_id': data['business_ids']
})

print(f"‚úÖ Loaded {len(metadata_df)} reviews")
print(f"   Columns: {list(metadata_df.columns)}")
print(f"   First review ID: {metadata_df.iloc[0]['review_id']}")
print(f"   Sample text: {metadata_df.iloc[0]['full_text'][:100]}...")

# Verify file sizes
print("\nüìä File sizes:")
sae_size = os.path.getsize(LOCAL_H5_SAE_PATH) / 1e9
meta_size = os.path.getsize(LOCAL_METADATA_PATH) / 1e9
print(f"  SAE features: {sae_size:.2f} GB")
print(f"  Metadata activations: {meta_size:.2f} GB")

# Load metadata into DataFrame
print("\nüìä Loading metadata into DataFrame...")
data = np.load(LOCAL_METADATA_PATH, allow_pickle=True)

# Create DataFrame from the individual arrays
metadata_df = pd.DataFrame({
    'review_id': data['review_ids'],
    'full_text': data['texts'],  # Note: renamed from 'texts' to match your original code
    'stars': data['stars'],
    'useful': data['useful'],
    'user_id': data['user_ids'],
    'business_id': data['business_ids']
})

print(f"‚úÖ Loaded {len(metadata_df)} reviews")
print(f"   Columns: {list(metadata_df.columns)}")
print(f"   First review ID: {metadata_df.iloc[0]['review_id']}")
print(f"   Sample text: {metadata_df.iloc[0]['full_text'][:100]}...")

"""# **Chapter 1:** Get Activations for a Specific Review

**W&B KEY:** 6cc2587f7ef0f0fc693e37cbd4aa52ba1400a52f

## Chapter 1.1: Load LLM and SAE Model
"""

class TopKSAE(nn.Module):
    def __init__(self, d_model, n_lat, k_act, baseline):
        super().__init__()
        self.W_dec = nn.Parameter(torch.randn(d_model, n_lat) / math.sqrt(d_model))
        self.W_enc = nn.Parameter(self.W_dec.t().clone())      # tied *init only*
        self.b_pre = nn.Parameter(baseline.clone())            # learnable
        self.k = k_act

    def forward(self, x):
        h = (x - self.b_pre) @ self.W_enc.t()                  # [B,n]
        top_idx = torch.topk(h, self.k, dim=-1).indices
        z = torch.zeros_like(h, dtype=h.dtype)
        z.scatter_(-1, top_idx, h.gather(-1, top_idx))
        x_hat = z @ self.W_dec.t() + self.b_pre
        return x_hat, z

# Load GPT-2 model (same as Chapter 1)
print("Loading GPT-2...")
model = HookedTransformer.from_pretrained("gpt2", device="cuda", dtype="float32")
LAYER_IDX = 8
HOOK = f"blocks.{LAYER_IDX}.hook_resid_pre"
D_MODEL = 768

# Copy SAE features
print(f"Copying MODEL")
shutil.copy(MODEL_PATH, LOCAL_MODEL_PATH)
print(f"‚úÖ Model copied to: {LOCAL_MODEL_PATH}")

checkpoint_path = LOCAL_MODEL_PATH
size_mb = os.path.getsize(checkpoint_path) / (1024*1024)
print(f"‚úì Using local checkpoint: {checkpoint_path} ({size_mb:.1f} MB)")

ckpt = torch.load(checkpoint_path, map_location="cpu")
print(f"‚úì Loaded checkpoint with step: {ckpt.get('step', 'unknown')}")

# Initialize SAE
D_MODEL = 768
EXPANSION = 32
K_ACTIVE = 32
N_LATENTS = EXPANSION * D_MODEL

ema_sae = TopKSAE(D_MODEL, N_LATENTS, K_ACTIVE, torch.zeros(D_MODEL))  # CPU first
ema_sae.load_state_dict(ckpt["ema_sae"])  # assumes key name matches your old flow
ema_sae.eval()
ema_sae = ema_sae.cuda()
print("‚úì SAE loaded successfully!")

"""## Chapter 1.2: Functions for Analyzing Text"""

def process_new_text(text, feature_indices_to_track):
    """Process arbitrary text and extract specific feature activations"""

    # Tokenize (same as Chapter 1)
    ids = tok(text, add_special_tokens=False).input_ids

    if tok.pad_token is None:
      tok.add_special_tokens({'pad_token': tok.eos_token})

    if not ids:
        return None

    # Create 64-token windows (same logic as Chapter 1)
    windows = []
    for i in range(0, len(ids), 64):
        window = ids[i:i+64]
        if len(window) < 64:
            # Pad the last window
            window = window + [tok.pad_token_id] * (64 - len(window))
        windows.append(window)

    windows_tensor = torch.tensor(windows).cuda()

    # Storage for activations
    all_activations = []

    # Hook to capture GPT-2 activations
    def save_acts(act, hook):
        # Same normalization as Chapter 1
        flat = act.detach().reshape(-1, D_MODEL)
        flat -= flat.mean(-1, keepdim=True)
        flat /= flat.norm(dim=-1, keepdim=True)
        all_activations.append(flat)

    # Run through GPT-2
    model.run_with_hooks(windows_tensor,
                        fwd_hooks=[(HOOK, save_acts)],
                        return_type=None)

    # Concatenate all activations
    gpt2_acts = torch.cat(all_activations, dim=0)  # Shape: (n_tokens, 768)

    # Run through SAE
    with torch.no_grad():
        x_hat, z = ema_sae(gpt2_acts)

    # Extract specific features
    tracked_features = {}
    for idx in feature_indices_to_track:
        tracked_features[f"feature_{idx}"] = z[:, idx].cpu().numpy()

    # Get tokens for reference
    tokens = tok.convert_ids_to_tokens(ids)

    return {
        "text": text,
        "tokens": tokens,
        "all_activations": z.cpu().numpy(),
        "tracked_features": tracked_features,
        "n_tokens": len(tokens)
    }

def process_text_for_analysis(text):
    """
    Common processing for text analysis functions
    Returns result dict with all features processed
    """
    all_features = list(range(N_LATENTS))
    return process_new_text(text, all_features)

def get_active_features(activations, top_k=None):
    """
    Get non-zero features and their values from activation array

    Args:
        activations: 1D array of activations for a single token
        top_k: If specified, return only top k features

    Returns:
        feature_indices: indices of active features (sorted by strength)
        feature_values: corresponding activation values (sorted)
    """
    non_zero_mask = activations > 0
    non_zero_features = np.where(non_zero_mask)[0]
    non_zero_values = activations[non_zero_mask]

    if len(non_zero_features) == 0:
        return np.array([]), np.array([])

    # Sort by activation strength (descending)
    sorted_indices = np.argsort(non_zero_values)[::-1]

    if top_k is not None:
        sorted_indices = sorted_indices[:top_k]

    return non_zero_features[sorted_indices], non_zero_values[sorted_indices]

def clean_token_for_display(token):
    """Clean GPT-2 token for display (handle ƒ† for spaces)"""
    return token.replace('ƒ†', ' ')

def get_feature_statistics(activations):
    """Get statistics for feature activations across tokens"""
    non_zero = activations[activations > 0]
    if len(non_zero) == 0:
        return {
            'active_count': 0,
            'active_rate': 0.0,
            'max': 0.0,
            'mean_when_active': 0.0
        }

    return {
        'active_count': np.sum(activations > 0),
        'active_rate': np.mean(activations > 0),
        'max': non_zero.max(),
        'mean_when_active': non_zero.mean()
    }

"""## 1.3 Generate Function which takes in arbitrary text and outputs top activations"""

def analyze_text_activations(text, top_k=5):
    """
    Analyze arbitrary text and show top activations for each token

    Args:
        text: The text to analyze
        top_k: Number of top features to show per token
    """
    print(f"üìù Analyzing text: {text[:100]}...")

    # Process text through pipeline
    result = process_text_for_analysis(text)

    print(f"\nüìä Found {result['n_tokens']} tokens")

    # For each token, find top activations
    for token_idx in range(min(result['n_tokens'], len(result['tokens']))):
        token = result['tokens'][token_idx]
        activations = result['all_activations'][token_idx]

        # Get active features
        feature_indices, feature_values = get_active_features(activations, top_k)

        print(f"\nüî§ Token {token_idx}: '{clean_token_for_display(token)}'")

        if len(feature_indices) == 0:
            print("   No active features")
        else:
            print(f"   Active features: {np.sum(activations > 0)}")
            print(f"   Top {len(feature_indices)} features:")

            for feat_idx, activation in zip(feature_indices, feature_values):
                print(f"     Feature {feat_idx}: {activation:.4f}")

    return result

def analyze_multiple_texts(texts_to_analyze, top_k_per_token=5, show_top_features=20, exclude_features=None):

    """
    Analyze multiple texts and find the most common features across them

    Args:
        texts_to_analyze: List of texts to analyze
        top_k_per_token: Number of top features to track per token
        show_top_features: Number of most common features to display
        exclude_features: List of feature indices to exclude from analysis
    """
    print(f"üìö Analyzing {len(texts_to_analyze)} texts...\n")

    # Track feature occurrences across texts
    feature_document_frequency = {}  # How many documents each feature appears in
    all_results = []

    # Process each text
    for text_idx, text in enumerate(texts_to_analyze):
        print(f"\n{'='*60}")
        print(f"Text {text_idx + 1}/{len(texts_to_analyze)}")
        print(f"{'='*60}")

        # Run analysis
        result = analyze_text_activations(text, top_k=top_k_per_token)
        all_results.append(result)

        # Track unique features in this text
        features_in_this_text = set()

        # Convert exclude_features to set for faster lookup
        if exclude_features is None:
            exclude_features_set = set()
        else:
            exclude_features_set = set(exclude_features)

        # Go through all tokens in this text
        for token_idx in range(min(result['n_tokens'], len(result['tokens']))):
            activations = result['all_activations'][token_idx]

            # Find all active features (not just top k)
            active_features = np.where(activations > 0)[0]

            # Filter out excluded features
            filtered_features = [f for f in active_features if f not in exclude_features_set]
            features_in_this_text.update(filtered_features)

        # Update document frequency
        for feature in features_in_this_text:
            feature_document_frequency[feature] = feature_document_frequency.get(feature, 0) + 1

        print(f"\nüìä Unique features in this text: {len(features_in_this_text)}")

    # Sort features by document frequency
    sorted_features = sorted(feature_document_frequency.items(),
                           key=lambda x: x[1],
                           reverse=True)

    # Display results
    print(f"\n{'='*60}")
    print(f"üèÜ MOST COMMON FEATURES ACROSS ALL {len(texts_to_analyze)} TEXTS")
    print(f"{'='*60}\n")

    print(f"Total unique features across all texts: {len(feature_document_frequency)}\n")

    print(f"Top {show_top_features} most common features:")
    print(f"{'Feature':<10} {'Appears in':<15} {'Percentage':<10}")
    print("-" * 40)

    for i, (feature, count) in enumerate(sorted_features[:show_top_features]):
        percentage = (count / len(texts_to_analyze)) * 100
        print(f"{feature:<10} {count:<15} {percentage:>6.1f}%")

    # Find features that appear in ALL texts
    universal_features = [feat for feat, count in sorted_features
                         if count == len(texts_to_analyze)]

    if universal_features:
        print(f"\nüåü Features appearing in ALL texts: {universal_features[:10]}")
        if len(universal_features) > 10:
            print(f"   (and {len(universal_features) - 10} more...)")

    # Find features unique to single texts
    unique_features = [feat for feat, count in sorted_features if count == 1]
    print(f"\nü¶Ñ Features unique to single texts: {len(unique_features)}")

    return sorted_features, all_results

"""## 1.4 Create Color-coded text"""

def visualize_feature_activation(text, feature_indices, show_overlap=True, activation_threshold=0.01, show_values_for_feature=None):
    """
    Visualize how one or more features activate across one or more texts

    Args:
        text: Single text string or list of texts to analyze
        feature_indices: Single feature index (int) or list of feature indices
        show_overlap: If True, show when multiple features activate on same token
        activation_threshold: Minimum activation value to show color (default 0.01)
        show_values_for_feature: Feature index to show activation values for (None = don't show values)
    """
    # Handle input normalization
    if isinstance(feature_indices, int):
        feature_indices = [feature_indices]

    if isinstance(text, str):
        texts = [text]
        is_single_text = True
    else:
        texts = text
        is_single_text = False

    # Define color schemes
    color_schemes = [
        {'name': 'green', 'rgb': (0, 255, 0), 'base': (0, 150, 0)},
        {'name': 'blue', 'rgb': (0, 100, 255), 'base': (0, 50, 200)},
        {'name': 'red', 'rgb': (255, 100, 100), 'base': (200, 0, 0)},
        {'name': 'purple', 'rgb': (200, 100, 255), 'base': (150, 0, 200)},
        {'name': 'orange', 'rgb': (255, 180, 0), 'base': (200, 140, 0)},
        {'name': 'teal', 'rgb': (0, 200, 200), 'base': (0, 150, 150)},
        {'name': 'pink', 'rgb': (255, 150, 200), 'base': (200, 100, 150)},
        {'name': 'yellow', 'rgb': (255, 255, 100), 'base': (180, 180, 0)},
    ]

    # Collect all HTML parts
    all_html_parts = []

    # Process all texts
    for text_idx, current_text in enumerate(texts):
        # Process text
        result = process_text_for_analysis(current_text)

        # Get actual tokens (not padding)
        n_actual_tokens = min(len(result['tokens']), result['all_activations'].shape[0])
        tokens = result['tokens'][:n_actual_tokens]

        # Get activations for each feature
        feature_data = {}
        for i, feat_idx in enumerate(feature_indices):
            activations = result['all_activations'][:n_actual_tokens, feat_idx]
            stats = get_feature_statistics(activations)

            if stats['active_count'] > 0:
                color_idx = 0 if len(feature_indices) == 1 else i % len(color_schemes)
                feature_data[feat_idx] = {
                    'activations': activations,
                    'stats': stats,
                    'color': color_schemes[color_idx]
                }

        # Add text header
        if not is_single_text:
            all_html_parts.append(f'<div style="margin-bottom: 10px; font-weight: bold;">Text {text_idx+1}: {current_text[:50]}...</div>')
            all_html_parts.append(f'<div style="margin: 2px 0; color:#a00; font-size:12px;">(tokens={n_actual_tokens})</div>')

        # Create visualization for this text
        all_html_parts.append('<div style="font-family: monospace; font-size: 16px; line-height: 2.5; margin-bottom: 20px;">')

        for i, token in enumerate(tokens):
            # Add chunk boundary marker every 64 tokens
            if i > 0 and i % 64 == 0:
                all_html_parts.append(
                    '<span style="color: red; font-weight: bold; font-size: 20px; margin: 0 5px;">|</span>'
                )

            display_token = clean_token_for_display(token)

            # Check which features are active for this token (above threshold)
            active_features = []
            for feat_idx, data in feature_data.items():
                if data['activations'][i] > activation_threshold:
                    intensity = data['activations'][i] / data['stats']['max']
                    active_features.append((feat_idx, intensity, data))

            # Check if we should show activation value for this token
            show_value = False
            value_to_show = 0
            if show_values_for_feature is not None and show_values_for_feature in feature_data:
                activation_value = feature_data[show_values_for_feature]['activations'][i]
                if activation_value > 0:
                    show_value = True
                    value_to_show = activation_value

            if not active_features:
                # No features active - gray text
                if show_value:
                    all_html_parts.append(
                        f'<span style="display: inline-block; text-align: center; margin: 1px;">'
                        f'<div style="font-size: 10px; color: #888;">{value_to_show:.3f}</div>'
                        f'<div style="color: #888; padding: 2px 4px;">{display_token}</div>'
                        f'</span>'
                    )
                else:
                    all_html_parts.append(
                        f'<span style="color: #888; padding: 2px 4px; margin: 1px;" '
                        f'title="Token {i}: {token} - No active features">'
                        f'{display_token}</span>'
                    )
            elif len(active_features) == 1:
                # Single feature visualization
                feat_idx, intensity, data = active_features[0]
                color_info = data['color']

                # Interpolate color based on intensity
                r = int(color_info['base'][0] + (color_info['rgb'][0] - color_info['base'][0]) * (1 - intensity))
                g = int(color_info['base'][1] + (color_info['rgb'][1] - color_info['base'][1]) * (1 - intensity))
                b = int(color_info['base'][2] + (color_info['rgb'][2] - color_info['base'][2]) * (1 - intensity))

                if show_value:
                    all_html_parts.append(
                        f'<span style="display: inline-block; text-align: center; margin: 1px;">'
                        f'<div style="font-size: 10px; color: rgb({r},{g},{b}); font-weight: bold;">{value_to_show:.3f}</div>'
                        f'<div style="color: rgb({r},{g},{b}); '
                        f'background-color: rgba({color_info["rgb"][0]},{color_info["rgb"][1]},{color_info["rgb"][2]},{intensity * 0.2}); '
                        f'padding: 2px 4px; border-radius: 3px; font-weight: bold;">'
                        f'{display_token}</div>'
                        f'</span>'
                    )
                else:
                    all_html_parts.append(
                        f'<span style="color: rgb({r},{g},{b}); '
                        f'background-color: rgba({color_info["rgb"][0]},{color_info["rgb"][1]},{color_info["rgb"][2]},{intensity * 0.2}); '
                        f'padding: 2px 4px; margin: 1px; border-radius: 3px; font-weight: bold;" '
                        f'title="Token {i}: {token}\nFeature {feat_idx}: {data["activations"][i]:.4f}">'
                        f'{display_token}</span>'
                    )
            else:
                # Multiple features active
                if show_overlap:
                    # Show with gradient
                    gradient_parts = []
                    tooltip_parts = [f"Token {i}: {token}"]

                    # Sort by activation strength
                    active_features.sort(key=lambda x: x[1], reverse=True)

                    for feat_idx, intensity, data in active_features:
                        color_info = data['color']
                        gradient_parts.append(
                            f'rgba({color_info["rgb"][0]},{color_info["rgb"][1]},{color_info["rgb"][2]},{intensity * 0.3})'
                        )
                        tooltip_parts.append(f"Feature {feat_idx}: {data['activations'][i]:.4f}")

                    if show_value:
                        all_html_parts.append(
                            f'<span style="display: inline-block; text-align: center; margin: 1px;">'
                            f'<div style="font-size: 10px; color: #333; font-weight: bold;">{value_to_show:.3f}</div>'
                            f'<div style="background: linear-gradient(90deg, {", ".join(gradient_parts)}); '
                            f'padding: 2px 4px; border-radius: 3px; '
                            f'border: 2px solid #333; font-weight: bold;" '
                            f'title="{chr(10).join(tooltip_parts)}">'
                            f'{display_token}</div>'
                            f'</span>'
                        )
                    else:
                        all_html_parts.append(
                            f'<span style="'
                            f'background: linear-gradient(90deg, {", ".join(gradient_parts)}); '
                            f'padding: 2px 4px; margin: 1px; border-radius: 3px; '
                            f'border: 2px solid #333; font-weight: bold;" '
                            f'title="{chr(10).join(tooltip_parts)}">'
                            f'{display_token}</span>'
                        )
                else:
                    # Show only strongest feature
                    feat_idx, intensity, data = max(active_features, key=lambda x: x[1])
                    color_info = data['color']

                    r = int(color_info['base'][0] + (color_info['rgb'][0] - color_info['base'][0]) * (1 - intensity))
                    g = int(color_info['base'][1] + (color_info['rgb'][1] - color_info['base'][1]) * (1 - intensity))
                    b = int(color_info['base'][2] + (color_info['rgb'][2] - color_info['base'][2]) * (1 - intensity))

                    if show_value:
                        all_html_parts.append(
                            f'<span style="display: inline-block; text-align: center; margin: 1px;">'
                            f'<div style="font-size: 10px; color: rgb({r},{g},{b}); font-weight: bold;">{value_to_show:.3f}</div>'
                            f'<div style="color: rgb({r},{g},{b}); '
                            f'background-color: rgba({color_info["rgb"][0]},{color_info["rgb"][1]},{color_info["rgb"][2]},{intensity * 0.2}); '
                            f'padding: 2px 4px; border-radius: 3px; font-weight: bold; '
                            f'border: 1px dashed #666;" '
                            f'title="Token {i}: {token}\nSTRONGEST: Feature {feat_idx}: {data["activations"][i]:.4f}\n'
                            f'(+{len(active_features)-1} other features)">'
                            f'{display_token}</div>'
                            f'</span>'
                        )
                    else:
                        all_html_parts.append(
                            f'<span style="color: rgb({r},{g},{b}); '
                            f'background-color: rgba({color_info["rgb"][0]},{color_info["rgb"][1]},{color_info["rgb"][2]},{intensity * 0.2}); '
                            f'padding: 2px 4px; margin: 1px; border-radius: 3px; font-weight: bold; '
                            f'border: 1px dashed #666;" '
                            f'title="Token {i}: {token}\nSTRONGEST: Feature {feat_idx}: {data["activations"][i]:.4f}\n'
                            f'(+{len(active_features)-1} other features)">'
                            f'{display_token}</span>'
                        )

        all_html_parts.append('</div>')

    # Add legend at the end
    all_html_parts.append('<div style="margin-top: 30px; padding: 10px; background-color: #f5f5f5; border-radius: 5px;">')
    all_html_parts.append('<strong>Legend:</strong><br>')

    for i, feat_idx in enumerate(feature_indices):
        color_idx = 0 if len(feature_indices) == 1 else i % len(color_schemes)
        color_info = color_schemes[color_idx]
        all_html_parts.append(
            f'<span style="color: rgb({color_info["base"][0]},{color_info["base"][1]},{color_info["base"][2]}); '
            f'background-color: rgba({color_info["rgb"][0]},{color_info["rgb"][1]},{color_info["rgb"][2]},0.2); '
            f'padding: 4px 8px; margin: 2px; border-radius: 3px; display: inline-block;">'
            f'Feature {feat_idx} ({color_info["name"]})</span> '
        )

    if show_values_for_feature is not None:
        all_html_parts.append(f'<br><br>Showing activation values for Feature {show_values_for_feature}')

    all_html_parts.append('</div>')

    # Display everything at once
    display(HTML(''.join(all_html_parts)))

"""## 1.5 Compare Token Activations for Two Pieces of Text"""

def compare_text_activations(text1, text2, top_k=20, aggregation='max'):
    """
    Compare two texts and find features with biggest activation differences

    Args:
        text1: First text to compare
        text2: Second text to compare
        top_k: Number of top differences to show (both positive and negative)
        aggregation: How to aggregate token-level activations ('max' or 'mean')
    """
    print(f"üìä Comparing feature activations between two texts\n")
    print(f"Text 1: {text1[:80]}...")
    print(f"Text 2: {text2[:80]}...\n")

    # Process both texts
    result1 = process_text_for_analysis(text1)
    result2 = process_text_for_analysis(text2)

    # Aggregate activations across tokens
    if aggregation == 'max':
        agg_func = np.max
        agg_name = "Max"
    else:
        agg_func = np.mean
        agg_name = "Mean"

    # Get aggregated activations for each text
    agg_acts1 = agg_func(result1['all_activations'], axis=0)
    agg_acts2 = agg_func(result2['all_activations'], axis=0)

    # Calculate differences (positive = more active in text1)
    differences = agg_acts1 - agg_acts2

    # Get indices sorted by absolute difference
    sorted_indices = np.argsort(np.abs(differences))[::-1]

    # Print results
    print(f"{'='*80}")
    print(f"TOP {top_k} FEATURES WITH BIGGEST DIFFERENCES ({agg_name} aggregation)")
    print(f"{'='*80}\n")

    print(f"{'Feature':<10} {'Text1':<12} {'Text2':<12} {'Difference':<12} {'Direction'}")
    print("-" * 70)

    for i in range(min(top_k, len(sorted_indices))):
        idx = sorted_indices[i]
        diff = differences[idx]
        val1 = agg_acts1[idx]
        val2 = agg_acts2[idx]

        if diff > 0:
            direction = "‚Üí Text1"
            color = "\033[92m"  # Green
        else:
            direction = "‚Üí Text2"
            color = "\033[94m"  # Blue

        print(f"{idx:<10} {val1:<12.4f} {val2:<12.4f} {color}{diff:>+12.4f}\033[0m {direction}")

    # Find features unique to each text
    unique_to_text1 = np.where((agg_acts1 > 0) & (agg_acts2 == 0))[0]
    unique_to_text2 = np.where((agg_acts1 == 0) & (agg_acts2 > 0))[0]

    print(f"\nüìå Features unique to Text 1: {len(unique_to_text1)}")
    if len(unique_to_text1) > 0:
        print(f"   Examples: {unique_to_text1[:10].tolist()}")

    print(f"\nüìå Features unique to Text 2: {len(unique_to_text2)}")
    if len(unique_to_text2) > 0:
        print(f"   Examples: {unique_to_text2[:10].tolist()}")

    # Optional: Visualize top differences
    print(f"\nüé® Visualizing top 5 positive differences (more active in Text 1):")
    top_positive = [sorted_indices[i] for i in range(len(sorted_indices))
                    if differences[sorted_indices[i]] > 0][:5]
    if top_positive:
        visualize_feature_activation([text1, text2], top_positive)

    print(f"\nüé® Visualizing top 5 negative differences (more active in Text 2):")
    top_negative = [sorted_indices[i] for i in range(len(sorted_indices))
                    if differences[sorted_indices[i]] < 0][:5]
    if top_negative:
        visualize_feature_activation([text1, text2], top_negative)

    return {
        'differences': differences,
        'sorted_indices': sorted_indices,
        'agg_acts1': agg_acts1,
        'agg_acts2': agg_acts2,
        'unique_to_text1': unique_to_text1,
        'unique_to_text2': unique_to_text2
    }

"""# Chapter 2: Interpretability Playground
Run everything in Chapter 0 and Chapter 1 before you run this

## 2.1 Find Biggest and Most Frequent Activations for a Set of Texts
"""

reviews = [
    "Arrived stale: Expiration date was 3 months ago and tastes like cardboard.",
    "Better than Starbucks!: Rich flavor, great price, will definitely order again.",
    "Not as advertised: Supposed to be medium roast but this is BURNT.",
    "5 stars!: Smooth, no bitterness, perfect for my morning routine.",
    "Package came damaged: Half the beans were crushed, waste of money.",
    "Amazing value: $15 for 2 pounds and tastes like the $30 brands.",
    "Gave me heartburn: Way too acidic, had to throw the whole bag away.",
    "Finally found my coffee!: Been searching for years, this is THE ONE.",
    "Inconsistent quality: First bag was great, second bag tasted completely different.",
    "Good but overpriced: Decent espresso but you can get the same quality for half the price."
]

excluded = [3079, 20, 3098, 5152, 3626, 1084, 4690, 1622, 3676, 5744, 5409, 3187, 5240, 4734, 142, 1169, 5792,
            3774, 717, 223, 5349, 238, 4337, 3836, 2328, 3865, 798, 5415, 2348, 2359,
            5437, 864, 2922, 4464, 4985, 3964, 5031, 3496, 5594, 2541, 10, 4415, 2374, 4562, 833, 3065, 1137, 5309, 5638, 1550,
            3615, 1725, 1779, 4062, 51, 107, 5908, 1886, 2013]

# Run analysis
feature_frequencies, results = analyze_multiple_texts(reviews,
                                                     top_k_per_token=3,
                                                     show_top_features=20, exclude_features=excluded)

# Optional: Visualize the most common features on a sample text
print("\n" + "="*60)
print("üé® VISUALIZING TOP 5 COMMON FEATURES ON FIRST TEXT")
print("="*60 + "\n")

top_5_features = [feat for feat, _ in feature_frequencies[:5]]
visualize_feature_activation(reviews[0], top_5_features)

"""## 2.2 Find when a (set of) features is activated in a text"""

phrases =   [
    # Testing possessive pattern: X's Y (X should be low, Y should be high)
    "The student's notebook contained detailed observations.",               # ACTIVATE on "notebook"
    "A person's character reveals itself under pressure.",                  # ACTIVATE on "character"
    "The building's foundation showed significant cracks.",                 # ACTIVATE on "foundation"
    "My neighbor's behavior has been concerning lately.",                   # ACTIVATE on "behavior"

    # Testing if ANY possessed noun activates
    "The tree's branches swayed in the wind.",                            # ACTIVATE on "branches"
    "The ocean's waves crashed against the shore.",                       # ACTIVATE on "waves"
    "A bird's nest fell from the oak.",                                   # ACTIVATE on "nest"
    "The sun's rays warmed the earth.",                                   # ACTIVATE on "rays"

    # Testing subject position with non-family/org terms
    "The bicycle rolled down the steep hill.",                            # ACTIVATE on "bicycle"
    "The computer crashed during the presentation.",                       # ACTIVATE on "computer"
    "Books lined every wall of the library.",                             # NOT ACTIVATE - plural subject
    "Happiness filled her heart completely.",                             # NOT ACTIVATE - abstract subject

    # Testing if possessive overrides semantic content
    "The criminal's methodology was surprisingly sophisticated.",          # ACTIVATE on "methodology"
    "A child's grandmother visited last week.",                           # ACTIVATE on "grandmother"
    "The artist's mother critiqued the painting.",                        # ACTIVATE on "mother"
    "My enemy's strategy proved effective.",                              # ACTIVATE on "strategy"

    # Testing object position (should NOT activate)
    "She visited her grandmother yesterday.",                             # NOT ACTIVATE - object position
    "They studied the methodology carefully.",                            # NOT ACTIVATE - object position
    "We bought a new machine today.",                                    # NOT ACTIVATE - object position
    "I joined the committee last month.",                                # NOT ACTIVATE - object position

    # Testing double possessives
    "The teacher's student's project won first place.",                  # ACTIVATE on "student" and "project"
    "My friend's sister's wedding was beautiful.",                       # ACTIVATE on "sister" and "wedding"
    "The company's CEO's decision surprised everyone.",                  # ACTIVATE on "CEO" and "decision"
    "A nation's people's voice must be heard.",                         # ACTIVATE on "people" and "voice"

    # Testing if determiners matter
    "That grandmother baked excellent cookies.",                          # ACTIVATE - demonstrative subject
    "This machine needs immediate repair.",                              # ACTIVATE - demonstrative subject
    "Some committees make poor decisions.",                              # NOT ACTIVATE - quantifier subject
    "Every methodology has its limitations.",                            # NOT ACTIVATE - universal quantifier

    # Testing grammatical vs semantic hierarchies
    "The democracy's structure promotes citizen participation.",          # ACTIVATE on "structure"
    "Chaos's opposite is order and stability.",                         # ACTIVATE on "opposite"
    "The anarchy's spread worried government officials.",                # ACTIVATE on "spread"
    "Freedom's price is eternal vigilance.",                            # ACTIVATE on "price"

    # Edge cases
    "Its methodology proved superior to alternatives.",                   # NOT ACTIVATE - "its" different?
    "Her analysis revealed surprising patterns.",                         # NOT ACTIVATE - pronoun possessive?
    "The the cat's toy rolled away.",                                   # ACTIVATE on "toy" despite error
    "Grandmother's faced difficult challenges.",                          # NOT ACTIVATE - no possessed noun

    # Testing if activation is about grammatical role or semantic possession
    "The store's owner called the police.",                              # ACTIVATE on "owner"
    "The owner's store was robbed yesterday.",                           # ACTIVATE on "store"
    "Methods of analysis vary significantly.",                            # NOT ACTIVATE - prepositional phrase
    "Analysis of methods revealed inconsistencies.",                      # NOT ACTIVATE - prepositional phrase
]

feature_idx = [17874]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""## 2.3 Find Differences between text activations"""

# Example usage
text1 = "This coffee is bold and tasty"
text2 = "This coffee is weak and disgusting"

results = compare_text_activations(text1, text2, top_k=20)

"""# Chapter 3: Look at Activations in Data

## 3.1 Inspect H5 File
"""

# H5 File Structure Inspector (Fixed)
def inspect_h5_structure(h5_path):
    """
    Thoroughly inspect H5 file structure to understand what we're working with
    """
    print(f"\n{'='*60}")
    print(f"H5 FILE STRUCTURE INSPECTION")
    print(f"{'='*60}")

    with h5py.File(h5_path, "r") as h5:
        print(f"\nFile: {h5_path}")
        print(f"Datasets found: {list(h5.keys())}\n")

        # Based on Chapter 3, we expect these datasets:
        expected = {
            'z_idx': 'Feature indices (sparse format)',
            'z_val': 'Feature values (sparse format)',
            'rev_idx': 'Token-to-review mapping',
            'review_ids_unique': 'List of unique review IDs'
        }

        for key in h5.keys():
            dataset = h5[key]
            print(f"üìÅ Dataset: '{key}'")
            print(f"   Shape: {dataset.shape}")
            print(f"   Dtype: {dataset.dtype}")

            if key in expected:
                print(f"   ‚úì {expected[key]}")

            # Show samples
            if key == 'z_idx':
                sample = dataset[0][:5]
                print(f"   Sample (first token): {sample}... (showing 5 of {dataset.shape[1]})")

            elif key == 'z_val':
                sample = dataset[0][:5]
                # Format each value individually
                formatted = [f"{v:.3f}" for v in sample]
                print(f"   Sample (first token): [{', '.join(formatted)}]... (showing 5 of {dataset.shape[1]})")

            elif key == 'rev_idx':
                sample = dataset[:5]
                decoded = []
                for s in sample:
                    if isinstance(s, bytes):
                        decoded.append(s.decode('utf-8'))
                    else:
                        decoded.append(str(s))
                print(f"   First 5 review IDs: {decoded}")

            elif key == 'review_ids_unique':
                print(f"   Total unique reviews: {len(dataset)}")
                sample = dataset[:3]
                decoded = []
                for s in sample:
                    if isinstance(s, bytes):
                        decoded.append(s.decode('utf-8'))
                    else:
                        decoded.append(str(s))
                print(f"   First 3: {decoded}")

            print()

        # Check consistency
        print(f"{'='*40}")
        print("CONSISTENCY CHECKS:")
        print(f"{'='*40}")

        if 'z_idx' in h5 and 'rev_idx' in h5:
            n_tokens_features = h5['z_idx'].shape[0]
            n_tokens_mapping = h5['rev_idx'].shape[0]

            if n_tokens_features == n_tokens_mapping:
                print(f"‚úì Token counts match: {n_tokens_features:,}")
            else:
                print(f"‚ùå TOKEN MISMATCH!")
                print(f"   Features: {n_tokens_features:,}")
                print(f"   Mapping: {n_tokens_mapping:,}")

        if 'z_idx' in h5:
            print(f"\n‚úì Using SPARSE format (z_idx + z_val)")
            print(f"  Each token has {h5['z_idx'].shape[1]} active features")

        print("\n‚ö†Ô∏è NOTE: Review texts are NOT in this file - they're in the NPZ!")

# Run the inspection
inspect_h5_structure(LOCAL_H5_SAE_PATH)

"""## 3.3 Helper Functions

Collapse this and hit run to load all helper functions at once

### 3.2.0 Misc Functions
"""

def get_review_text(review_id, df):
    """
    Get the full text for a specific review ID

    Args:
        review_id: The review ID (e.g., 'AMZ_ESP_000001')
        df: DataFrame containing the reviews (with 'review_id' and 'full_text' columns)

    Returns:
        str: The review text, or None if not found
    """

    # Find the review
    match = df[df['review_id'] == review_id]

    if len(match) == 0:
        return None

    return match.iloc[0]['full_text']

def create_word_removal_array(text):
    """
    Create an array of strings where each removes one word from the start

    Args:
        text: Input string

    Returns:
        List of progressively shortened strings
    """
    # Find runs of non-whitespace and take suffixes of the ORIGINAL string.
    spans = list(re.finditer(r'\S+', text))
    return [text[m.start():] for m in spans]

# Example usage:
text = "The quick brown fox jumps"
removal_array = create_word_removal_array(text)
print(removal_array)
# Output: ['The quick brown fox jumps', 'quick brown fox jumps', 'brown fox jumps', 'fox jumps', 'jumps']

"""### 3.2.1 Function for getting activation for a specific token and feature from Sparse format used in H5 file"""

def get_feature_activation_for_token(h5_sae, token_idx, feature_idx):
    """
    Get activation value for a specific token and feature from SPARSE format
    """
    # Get the active features and values for this token
    active_features = h5_sae['z_idx'][token_idx]
    active_values = h5_sae['z_val'][token_idx]

    # Find if our feature is in the active set
    feature_position = np.where(active_features == feature_idx)[0]

    if len(feature_position) > 0:
        return float(active_values[feature_position[0]])
    else:
        return 0.0

def get_feature_activations_chunk(h5_sae, feature_idx, start_token, end_token):
    """
    Get activation values for a specific feature across a range of tokens
    Handles the SPARSE format efficiently
    """
    chunk_size = end_token - start_token
    activations = np.zeros(chunk_size, dtype=np.float32)

    # Get the chunk of indices and values
    indices_chunk = h5_sae['z_idx'][start_token:end_token]
    values_chunk = h5_sae['z_val'][start_token:end_token]

    # Vectorized search for the feature
    for i in range(chunk_size):
        # Find where feature_idx appears in this token's active features
        mask = indices_chunk[i] == feature_idx
        if np.any(mask):
            # Get the corresponding value
            activations[i] = values_chunk[i][mask][0]

    return activations

"""### 3.2.2 Function for loading review text from csv metadata"""

def load_review_texts_from_df(metadata_df, review_id_column='review_id', text_column='full_text'):
    """
    Load review texts from metadata DataFrame and create lookup dictionary

    Args:
        metadata_df: DataFrame containing review metadata (already loaded from NPZ)
        review_id_column: Name of the column containing review IDs
        text_column: Name of the column containing review texts

    Returns:
        dict: Mapping of review_id -> text
    """
    print(f"\nüìÑ Creating review lookup from metadata DataFrame...")
    print(f"   Working with {len(metadata_df)} rows")
    print(f"   Columns: {list(metadata_df.columns)}")

    # Check if expected columns exist
    if review_id_column not in metadata_df.columns:
        raise ValueError(f"Column '{review_id_column}' not found in CSV!")
    if text_column not in metadata_df.columns:
        raise ValueError(f"Column '{text_column}' not found in CSV!")

    # Create the lookup dictionary
    review_lookup = {}
    empty_texts = 0

    for idx, row in metadata_df.iterrows():
        review_id = str(row[review_id_column])  # Ensure it's a string
        text = str(row[text_column])

        if pd.isna(row[text_column]) or text == 'nan' or text.strip() == '':
            empty_texts += 1
            text = ""  # Use empty string for missing texts

        review_lookup[review_id] = text

    print(f"   Created lookup with {len(review_lookup)} reviews")
    if empty_texts > 0:
        print(f"   ‚ö†Ô∏è  Warning: {empty_texts} reviews had empty/missing text")

    return review_lookup

# Test loading the metadata
review_lookup = load_review_texts_from_df(metadata_df)

# Verify it matches the H5 file
print("\nüîç Verifying DataFrame matches H5 file...")
with h5py.File(LOCAL_H5_SAE_PATH, "r") as h5:
    print(f"   Available keys in H5: {list(h5.keys())}")

    # Get unique review IDs from rev_idx
    print("   Extracting unique review IDs from rev_idx...")

    # Get first 2000 review IDs to check
    sample_rev_ids = h5['rev_idx'][:2000]

    # Get unique IDs from sample
    unique_ids = []
    seen = set()
    for rid in sample_rev_ids:
        if isinstance(rid, bytes):
            rid_str = rid.decode('utf-8')
        else:
            rid_str = str(rid)

        if rid_str not in seen:
            unique_ids.append(rid_str)
            seen.add(rid_str)
            if len(unique_ids) >= 10:  # Just check first 10 unique
                break

    print(f"   Found {len(unique_ids)} unique review IDs to verify")

    # Check if they exist in our lookup
    all_found = True
    for rid in unique_ids:
        if rid not in review_lookup:
            print(f"   ‚ùå Review {rid} from H5 not found in DataFrame!")
            all_found = False
        else:
            text_preview = review_lookup[rid][:50] + "..." if len(review_lookup[rid]) > 50 else review_lookup[rid]
            print(f"   ‚úì {rid}: {text_preview}")

    if all_found:
        print(f"\n‚úÖ All checked reviews found in DataFrame!")

"""### 3.2.3 Function for combining Metadata with SAE Activation Data"""

def load_combined_data(h5_path, metadata_df):
    """
    Load and combine data from both H5 file and metadata DataFrame.
    Note that this function does "lazy loading" from the H5 file, which only draws data when it's needed saving memory space

    Returns:
        dict with:
        - review_lookup: dict mapping review_id -> text
        - h5_path: path to H5 file for lazy loading
        - n_tokens: total number of tokens
        - n_reviews: total number of reviews
        - review_ids_unique: array of unique review IDs
    """
    # Load CSV
    review_lookup = load_review_texts_from_df(metadata_df)

    # Get H5 metadata
    with h5py.File(h5_path, "r") as h5:
        n_tokens = h5['z_idx'].shape[0]

        # Get unique review IDs from rev_idx
        all_rev_ids = h5['rev_idx'][:]

        # Extract unique IDs
        unique_ids_set = set()
        for rid in all_rev_ids:
            if isinstance(rid, bytes):
                unique_ids_set.add(rid.decode('utf-8'))
            else:
                unique_ids_set.add(str(rid))

        decoded_ids = list(unique_ids_set)

    return {
        'review_lookup': review_lookup,
        'h5_path': h5_path,
        'n_tokens': n_tokens,
        'n_reviews': len(decoded_ids),
        'review_ids_unique': decoded_ids
    }

# Test the combined loader
combined_data = load_combined_data(LOCAL_H5_SAE_PATH, metadata_df)
print(f"\nüìä Combined data summary:")
print(f"   Total tokens: {combined_data['n_tokens']:,}")
print(f"   Total reviews: {combined_data['n_reviews']:,}")
print(f"   Reviews in Metadata: {len(combined_data['review_lookup']):,}")

"""### 3.2.4 Function for Extracting Context Around Token Activation"""

def _extract_single_context_df(global_idx, rev_id_str, activation,
                                review_lookup, review_token_positions,
                                context_before, context_after, tok):
    """
    Extract context for a single token position using review texts from DataFrame

    Args:
        global_idx: Token position in the full dataset
        rev_id_str: Review ID string
        activation: Activation value for this token
        review_lookup: Dict mapping review_id -> text
        review_token_positions: Dict mapping review_id -> list of token positions
        context_before: Number of tokens before to include
        context_after: Number of tokens after to include
        tok: Tokenizer instance
    """
    # Get review text from lookup
    review_text = review_lookup.get(rev_id_str)
    if review_text is None:
        return None

    # Get all positions for this review
    positions_in_review = review_token_positions.get(rev_id_str, [])
    if global_idx not in positions_in_review:
        return None

    # Find local position within review
    local_position = positions_in_review.index(global_idx)

    # Tokenize the review
    tokens = tok(review_text, add_special_tokens=False).input_ids
    token_strings = tok.convert_ids_to_tokens(tokens)

    if local_position >= len(token_strings):
        return None

    # Extract context window
    start = max(0, local_position - context_before)
    end = min(len(token_strings), local_position + context_after + 1)

    context_tokens = token_strings[start:end]
    context_str = ' '.join([t.replace('ƒ†', ' ') for t in context_tokens])

    # Position of active token in context
    active_token_position_in_context = local_position - start

    return {
        'context': context_str,
        'active_token': token_strings[local_position].replace('ƒ†', ' '),
        'position': local_position,
        'activation': float(activation),
        'token_range': (start, end),
        'active_position_in_context': active_token_position_in_context,
        'review_id': rev_id_str,
        'review_text': review_text,
        'global_position': global_idx
    }

"""### 3.2.5 Function for extracting feature data"""

def extract_feature_data_adapted(feature_idx, h5_sae_path, metadata_df,
                                max_active_samples=50_000,
                                n_inactive_samples=2_000,
                                context_before=20,
                                context_after=10):
    """
    Extract feature data adapted for espresso dataset structure

    Args:
        feature_idx: Feature index to analyze
        h5_sae_path: Path to SAE features H5 file
        metadata_df: DataFrame containing review metadata
        max_active_samples: Maximum active contexts to collect
        n_inactive_samples: Number of inactive contexts for comparison
        context_before: Tokens before active token to include
        context_after: Tokens after active token to include
    """

    print(f"\nüìä Extracting data for feature {feature_idx}")
    print(f"   Max active samples: {max_active_samples:,}")
    print(f"   Inactive samples: {n_inactive_samples:,}")
    print(f"   Context window: {context_before} before, {context_after} after")

    # Initialize tokenizer at the beginning
    from transformers import AutoTokenizer
    tok = AutoTokenizer.from_pretrained("gpt2")
    if tok.pad_token is None:
        tok.add_special_tokens({'pad_token': tok.eos_token})

    # Load review texts from df
    print("\nüìÑ Loading review texts from Metadata...")
    review_lookup = load_review_texts_from_df(metadata_df)

    failed_contexts = 0
    active_contexts = []
    inactive_contexts = []
    token_counts = defaultdict(int)
    review_data = defaultdict(lambda: {
        'text': None,
        'active_contexts': [],
        'max_activation': 0.0,
        'n_active_tokens': 0
    })

    with h5py.File(h5_sae_path, "r") as h5_sae:
        # Get dimensions
        total_tokens = h5_sae["z_idx"].shape[0]
        print(f"   Total tokens in dataset: {total_tokens:,}")

        print(f"   Found {len(review_lookup)} reviews in DataFrame")

        # Pre-compute token positions for each review
        print("   Pre-computing review token mappings...")
        review_token_positions = defaultdict(list)

        chunk_size = 100_000
        for start in tqdm(range(0, total_tokens, chunk_size), desc="Building token map"):
            end = min(start + chunk_size, total_tokens)
            chunk_rev_ids = h5_sae["rev_idx"][start:end]

            for local_idx, rev_id in enumerate(chunk_rev_ids):
                if isinstance(rev_id, bytes):
                    rev_id_str = rev_id.decode('utf-8')
                else:
                    rev_id_str = str(rev_id)
                global_idx = start + local_idx
                review_token_positions[rev_id_str].append(global_idx)

        # Now scan for active tokens using sparse format
        total_active_found = 0

        for start in tqdm(range(0, total_tokens, chunk_size), desc="Scanning for active tokens"):
            end = min(start + chunk_size, total_tokens)

            # Use our helper function to get activations for this feature
            chunk_acts = get_feature_activations_chunk(h5_sae, feature_idx, start, end)
            chunk_rev_ids = h5_sae["rev_idx"][start:end]

            # Find active tokens
            active_indices = np.where(chunk_acts > 0)[0]

            if len(active_indices) > 0:
                # Process active tokens
                for local_idx in active_indices:
                    if len(active_contexts) >= max_active_samples:
                        total_active_found += len(active_indices) - list(active_indices).index(local_idx)
                        break

                    global_idx = start + local_idx
                    activation = chunk_acts[local_idx]
                    rev_id = chunk_rev_ids[local_idx]

                    if isinstance(rev_id, bytes):
                        rev_id_str = rev_id.decode('utf-8')
                    else:
                        rev_id_str = str(rev_id)

                    # Get context using our CSV-based function
                    context_info = _extract_single_context_df(
                        global_idx, rev_id_str, activation,
                        review_lookup, review_token_positions,
                        context_before, context_after, tok
                    )

                    if context_info:
                        active_contexts.append(context_info)
                        total_active_found += 1

                        # Update token counts
                        token_counts[context_info['active_token']] += 1

                        # Update review data
                        review_data[rev_id_str]['active_contexts'].append(context_info)
                        review_data[rev_id_str]['n_active_tokens'] += 1
                        review_data[rev_id_str]['max_activation'] = max(
                            review_data[rev_id_str]['max_activation'],
                            activation
                        )
                        if review_data[rev_id_str]['text'] is None:
                            review_data[rev_id_str]['text'] = context_info.get('review_text', '')
                    else:
                        failed_contexts += 1

            # Collect inactive contexts
            if len(inactive_contexts) < n_inactive_samples:
                inactive_indices = np.where(chunk_acts == 0)[0]

                if len(inactive_indices) > 0:
                    n_needed = min(
                        len(inactive_indices),
                        n_inactive_samples - len(inactive_contexts)
                    )
                    sampled = np.random.choice(inactive_indices, n_needed, replace=False)

                    for local_idx in sampled:
                        global_idx = start + local_idx
                        rev_id = chunk_rev_ids[local_idx]

                        if isinstance(rev_id, bytes):
                            rev_id_str = rev_id.decode('utf-8')
                        else:
                            rev_id_str = str(rev_id)

                        context_info = _extract_single_context_df(
                            global_idx, rev_id_str, 0.0,
                            review_lookup, review_token_positions,
                            context_before, context_after, tok
                        )

                        if context_info:
                            inactive_contexts.append(context_info['context'])

            # Stop if we have enough active samples
            if len(active_contexts) >= max_active_samples:
                print(f"\n‚ö†Ô∏è  Reached maximum active samples limit ({max_active_samples:,})")
                print(f"   Total active tokens in dataset: >{total_active_found:,}")
                break

    print(f"\n‚úÖ Data extraction complete:")
    print(f"   Active contexts collected: {len(active_contexts):,}")
    print(f"   Inactive contexts collected: {len(inactive_contexts):,}")
    print(f"   Unique reviews: {len(review_data):,}")
    print(f"   Unique tokens: {len(token_counts):,}")
    print(f"   Failed contexts: {failed_contexts}")

    # Get top tokens for summary
    top_tokens = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)[:10]
    print(f"\n   Top 10 most frequent tokens:")
    for token, count in top_tokens:
        print(f"     '{token}': {count} times ({count/len(active_contexts)*100:.1f}%)")

    return {
        'feature_idx': feature_idx,
        'active_contexts': active_contexts,
        'active_reviews': dict(review_data),
        'inactive_contexts': inactive_contexts,
        'token_counts': dict(token_counts),
        'stats': {
            'total_active_found': total_active_found,
            'total_collected': len(active_contexts),
            'hit_limit': len(active_contexts) >= max_active_samples,
            'n_reviews': len(review_data),
            'n_inactive': len(inactive_contexts),
            'context_before': context_before,
            'context_after': context_after,
            'failed_contexts': failed_contexts
        }
    }

"""### 3.2.6 Function for Analyzing Most Active Tokens for a Feature"""

### 3.2.6 Function for Analyzing Most Active Tokens for a Feature

def analyze_feature_tokens_with_text(feature_idx, h5_sae_path, metadata_df,
                                   top_k=20, max_samples=50000):
    """
    Analyze which actual tokens (words/subwords) most strongly activate for a feature

    Args:
        feature_idx: Feature index to analyze
        h5_sae_path: Path to SAE features H5 file
        metadata_df: DataFrame containing review metadata
        top_k: Number of top tokens to show
        max_samples: Maximum number of active tokens to analyze
    """
    print(f"\nüìä Analyzing actual token patterns for feature {feature_idx}")

    # Initialize tokenizer
    from transformers import AutoTokenizer
    tok = AutoTokenizer.from_pretrained("gpt2")

    # Load review texts
    review_lookup = load_review_texts_from_df(metadata_df)

    # Storage for token statistics
    token_activations = defaultdict(list)
    token_counts = defaultdict(int)
    max_activations = defaultdict(float)
    bigrams = Counter()
    trigrams = Counter()
    bigram_examples = {}
    trigram_examples = {}

    # Track review token positions
    review_token_cache = {}
    samples_collected = 0

    with h5py.File(h5_sae_path, "r") as h5_sae:
        total_tokens = h5_sae["z_idx"].shape[0]
        chunk_size = 50_000

        # Build global position mapping for accurate token positioning
        review_token_positions = defaultdict(list)
        with tqdm(total=total_tokens, desc="Building position map") as pbar:
            chunk_size_mapping = 100_000
            for start_idx in range(0, total_tokens, chunk_size_mapping):
                end_idx = min(start_idx + chunk_size_mapping, total_tokens)
                chunk_rev_ids = h5_sae["rev_idx"][start_idx:end_idx]

                for local_idx, rev_id in enumerate(chunk_rev_ids):
                    if isinstance(rev_id, bytes):
                        rev_id_str = rev_id.decode('utf-8')
                    else:
                        rev_id_str = str(rev_id)
                    global_idx = start_idx + local_idx
                    review_token_positions[rev_id_str].append(global_idx)

                pbar.update(end_idx - start_idx)

        for start in tqdm(range(0, total_tokens, chunk_size), desc="Scanning for active tokens"):
            if samples_collected >= max_samples:
                break

            end = min(start + chunk_size, total_tokens)

            # Get activations and review IDs
            chunk_acts = get_feature_activations_chunk(h5_sae, feature_idx, start, end)
            chunk_rev_ids = h5_sae["rev_idx"][start:end]

            # Find active tokens
            active_indices = np.where(chunk_acts > 0)[0]

            for local_idx in active_indices:
                if samples_collected >= max_samples:
                    break

                activation = chunk_acts[local_idx]
                rev_id = chunk_rev_ids[local_idx]

                if isinstance(rev_id, bytes):
                    rev_id_str = rev_id.decode('utf-8')
                else:
                    rev_id_str = str(rev_id)

                # Get or cache tokenized review
                if rev_id_str not in review_token_cache:
                    review_text = review_lookup.get(rev_id_str, "")
                    if not review_text:
                        continue
                    tokens = tok(review_text, add_special_tokens=False).input_ids
                    token_strings = tok.convert_ids_to_tokens(tokens)
                    review_token_cache[rev_id_str] = token_strings

                token_strings = review_token_cache[rev_id_str]

                # Find position in review using global mapping
                global_position = start + local_idx
                positions_in_review = review_token_positions[rev_id_str]
                try:
                    tokens_before = positions_in_review.index(global_position)
                except ValueError:
                    # Position not found - should not happen but handle gracefully
                    continue

                if tokens_before < len(token_strings):
                    token = token_strings[tokens_before].replace('ƒ†', ' ')

                    # Update statistics
                    token_activations[token].append(activation)
                    token_counts[token] += 1
                    max_activations[token] = max(max_activations[token], activation)
                    samples_collected += 1

                    # Extract bigrams and trigrams around the active token
                    # Bigrams (token before + active token, active token + token after)
                    if tokens_before > 0:
                      bigram_before = token_strings[tokens_before-1].replace('ƒ†', ' ') + " " + token
                      bigrams[bigram_before] += 1
                      if bigram_before not in bigram_examples and tokens_before >= 2:
                          # Get a bit more context for the example
                          context_start = max(0, tokens_before-10)
                          context_end = min(len(token_strings), tokens_before+10)
                          example = ''.join([t.replace('ƒ†', ' ') for t in token_strings[context_start:context_end]])
                          bigram_examples[bigram_before] = example.strip()

                    if tokens_before < len(token_strings) - 1:
                        bigram_after = token + " " + token_strings[tokens_before+1].replace('ƒ†', ' ')
                        bigrams[bigram_after] += 1
                        if bigram_after not in bigram_examples:
                            context_start = max(0, tokens_before-2)
                            context_end = min(len(token_strings), tokens_before+3)
                            example = ''.join([t.replace('ƒ†', ' ') for t in token_strings[context_start:context_end]])
                            bigram_examples[bigram_after] = example.strip()

                    # Trigrams (including active token)
                    if tokens_before > 0 and tokens_before < len(token_strings) - 1:
                        trigram = (token_strings[tokens_before-1].replace('ƒ†', ' ') + " " +
                                  token + " " +
                                  token_strings[tokens_before+1].replace('ƒ†', ' '))
                        trigrams[trigram] += 1
                        if trigram not in trigram_examples:
                            context_start = max(0, tokens_before-10)
                            context_end = min(len(token_strings), tokens_before+10)
                            example = ''.join([t.replace('ƒ†', ' ') for t in token_strings[context_start:context_end]])
                            trigram_examples[trigram] = example.strip()

    # Calculate average activations
    avg_activations = {}
    for token, acts in token_activations.items():
        avg_activations[token] = np.mean(acts)

    # Get top tokens
    top_by_count = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)[:top_k]
    top_by_max = sorted(max_activations.items(), key=lambda x: x[1], reverse=True)[:top_k]
    top_by_avg = sorted(avg_activations.items(), key=lambda x: x[1], reverse=True)[:top_k]

    # Create enhanced visualizations
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'Token Activation Analysis for Feature {feature_idx}', fontsize=16)

    # Plot 1: Most frequent tokens
    if top_by_count:
        ax1 = axes[0, 0]
        tokens, counts = zip(*top_by_count)
        bars1 = ax1.barh(range(len(tokens)), counts, color='steelblue')
        ax1.set_yticks(range(len(tokens)))
        ax1.set_yticklabels([f"'{t}'" for t in tokens])
        ax1.set_xlabel('Activation Count')
        ax1.set_title(f'Top {len(tokens)} Most Frequently Activated Tokens')
        ax1.invert_yaxis()

        # Add value labels
        for i, (bar, count) in enumerate(zip(bars1, counts)):
            ax1.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,
                    str(count), va='center')

    # Plot 2: Strongest max activations
    if top_by_max:
        ax2 = axes[0, 1]
        tokens, max_acts = zip(*top_by_max)
        bars2 = ax2.barh(range(len(tokens)), max_acts, color='coral')
        ax2.set_yticks(range(len(tokens)))
        ax2.set_yticklabels([f"'{t}'" for t in tokens])
        ax2.set_xlabel('Max Activation Value')
        ax2.set_title(f'Top {len(tokens)} Tokens by Peak Activation')
        ax2.invert_yaxis()

        # Add value labels
        for i, (bar, val) in enumerate(zip(bars2, max_acts)):
            ax2.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,
                    f'{val:.3f}', va='center')

    # Plot 3: Most common bigrams
    ax3 = axes[1, 0]
    top_bigrams = bigrams.most_common(top_k)
    if top_bigrams:
        bigram_texts, bigram_counts = zip(*top_bigrams)
        bars3 = ax3.barh(range(len(bigram_texts)), bigram_counts, color='mediumseagreen')
        ax3.set_yticks(range(len(bigram_texts)))
        ax3.set_yticklabels([f"'{b}'" for b in bigram_texts], fontsize=10)
        ax3.set_xlabel('Count')
        ax3.set_title(f'Top {len(bigram_texts)} Most Common Bigrams')
        ax3.invert_yaxis()

        # Add value labels
        for i, (bar, count) in enumerate(zip(bars3, bigram_counts)):
            ax3.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,
                    str(count), va='center')

    # Plot 4: Most common trigrams
    ax4 = axes[1, 1]
    top_trigrams = trigrams.most_common(top_k//2)  # Show fewer trigrams as they're longer
    if top_trigrams:
        trigram_texts, trigram_counts = zip(*top_trigrams)
        bars4 = ax4.barh(range(len(trigram_texts)), trigram_counts, color='mediumpurple')
        ax4.set_yticks(range(len(trigram_texts)))
        ax4.set_yticklabels([f"'{t}'" for t in trigram_texts], fontsize=9)
        ax4.set_xlabel('Count')
        ax4.set_title(f'Top {len(trigram_texts)} Most Common Trigrams')
        ax4.invert_yaxis()

        # Add value labels
        for i, (bar, count) in enumerate(zip(bars4, trigram_counts)):
            ax4.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,
                    str(count), va='center', fontsize=9)

    plt.tight_layout()
    plt.show()

    # Print detailed statistics
    print(f"\nüìà Detailed Statistics:")
    print(f"   Total active tokens analyzed: {samples_collected:,}")
    print(f"   Unique tokens found: {len(token_counts):,}")

    print(f"\nüèÜ Top 10 Most Frequent Tokens:")
    for i, (token, count) in enumerate(top_by_count[:10]):
        pct = (count / samples_collected) * 100
        print(f"   {i+1:2d}. '{token}': {count} times ({pct:.1f}%)")

    print(f"\nüí™ Top 10 Strongest Activations:")
    for i, (token, max_act) in enumerate(top_by_max[:10]):
        avg = avg_activations[token]
        print(f"   {i+1:2d}. '{token}': max={max_act:.4f}, avg={avg:.4f}")

    print(f"\nüìù Top 10 Bigrams with Examples:")
    for i, (bigram, count) in enumerate(bigrams.most_common(10)):
        example = bigram_examples.get(bigram, "No example captured")
        print(f"   {i+1:2d}. '{bigram}' ({count} times)")
        print(f"       Example: ...{example}...")

    print(f"\nüìù Top 10 Trigrams with Examples:")
    for i, (trigram, count) in enumerate(trigrams.most_common(10)):
        example = trigram_examples.get(trigram, "No example captured")
        print(f"   {i+1:2d}. '{trigram}' ({count} times)")
        print(f"       Example: ...{example}...")

    return {
        'token_counts': dict(token_counts),
        'max_activations': dict(max_activations),
        'avg_activations': avg_activations,
        'top_by_count': top_by_count,
        'top_by_max': top_by_max,
        'top_bigrams': bigrams.most_common(top_k),
        'top_trigrams': trigrams.most_common(top_k//2),
        'samples_analyzed': samples_collected,
        'bigram_examples': bigram_examples,
        'trigram_examples': trigram_examples,
    }

"""###3.2.7 Function for getting CSV list of activated tokens with token frequency and average activation"""

def analyze_feature_to_tokens_csv(feature_idx, h5_path, metadata_df, max_samples=100000, output_filename=None):
    """
    Analyze which tokens a specific feature activates on and create downloadable CSV

    Args:
        feature_idx: Feature ID to analyze
        h5_path: Path to H5 file with SAE activations
        metadata_df: DataFrame with review metadata
        max_samples: Maximum number of activations to analyze
        output_filename: Optional filename for CSV
    """

    # Initialize tokenizer
    from transformers import AutoTokenizer
    tok = AutoTokenizer.from_pretrained("gpt2")

    print(f"Analyzing feature {feature_idx}")

    # Load review texts
    review_lookup = load_review_texts_from_df(metadata_df)

    # Storage for token statistics
    token_stats = defaultdict(lambda: {'count': 0, 'sum': 0.0, 'examples': []})
    total_activations = 0

    # Build review position mapping and process activations
    with h5py.File(h5_path, "r") as h5:
        total_tokens = h5['z_idx'].shape[0]

        # First build position to review mapping
        print("Building position mapping...")
        review_token_positions = defaultdict(list)
        chunk_size = 100_000

        for start in tqdm(range(0, total_tokens, chunk_size), desc="Mapping positions"):
            end = min(start + chunk_size, total_tokens)
            chunk_rev_ids = h5['rev_idx'][start:end]

            for local_idx, rev_id in enumerate(chunk_rev_ids):
                if isinstance(rev_id, bytes):
                    rev_id_str = rev_id.decode('utf-8')
                else:
                    rev_id_str = str(rev_id)
                global_idx = start + local_idx
                review_token_positions[rev_id_str].append(global_idx)

        # Cache tokenized reviews
        review_token_cache = {}

        # Now scan for feature activations
        print(f"Scanning for feature {feature_idx} activations...")
        for start in tqdm(range(0, total_tokens, chunk_size), desc="Finding activations"):
            if total_activations >= max_samples:
                break

            end = min(start + chunk_size, total_tokens)

            # Get activations for this feature in chunk
            chunk_acts = get_feature_activations_chunk(h5, feature_idx, start, end)
            chunk_rev_ids = h5['rev_idx'][start:end]

            # Find active tokens
            active_indices = np.where(chunk_acts > 0)[0]

            for local_idx in active_indices:
                if total_activations >= max_samples:
                    break

                activation_value = float(chunk_acts[local_idx])
                global_idx = start + local_idx
                rev_id = chunk_rev_ids[local_idx]

                if isinstance(rev_id, bytes):
                    rev_id_str = rev_id.decode('utf-8')
                else:
                    rev_id_str = str(rev_id)

                # Get or cache tokenized review
                if rev_id_str not in review_token_cache:
                    review_text = review_lookup.get(rev_id_str, "")
                    if not review_text:
                        continue
                    tokens = tok(review_text, add_special_tokens=False).input_ids
                    token_strings = tok.convert_ids_to_tokens(tokens)
                    review_token_cache[rev_id_str] = (tokens, token_strings)

                token_ids, token_strings = review_token_cache[rev_id_str]

                # Find position in review
                positions_in_review = review_token_positions[rev_id_str]
                try:
                    token_position_in_review = positions_in_review.index(global_idx)
                except ValueError:
                    continue

                if token_position_in_review < len(token_ids):
                    token_id = token_ids[token_position_in_review]
                    token_string = token_strings[token_position_in_review].replace('ƒ†', ' ')

                    # Update statistics
                    token_stats[token_id]['count'] += 1
                    token_stats[token_id]['sum'] += activation_value
                    token_stats[token_id]['token_string'] = token_string

                    # Keep a few examples
                    if len(token_stats[token_id]['examples']) < 3:
                        token_stats[token_id]['examples'].append(activation_value)

                    total_activations += 1

    print(f"Found {total_activations} total activations across {len(token_stats)} unique tokens")

    # Prepare CSV data
    csv_data = []
    for token_id, stats in token_stats.items():
        csv_data.append({
            'token_id': token_id,
            'token_string': stats['token_string'],
            'count': stats['count'],
            'frequency': stats['count'] / total_activations if total_activations > 0 else 0,
            'average_activation': stats['sum'] / stats['count'] if stats['count'] > 0 else 0,
            'total_activation': stats['sum'],
            'example_values': ','.join([f"{v:.4f}" for v in stats['examples'][:3]])
        })

    # Sort by count (most frequent first)
    csv_data.sort(key=lambda x: x['count'], reverse=True)

    # Create CSV in memory
    output = io.StringIO()
    fieldnames = ['token_id', 'token_string', 'count', 'frequency',
                  'average_activation', 'total_activation', 'example_values']

    writer = csv.DictWriter(output, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(csv_data)

    # Add summary info
    summary = f"# Feature Analysis Summary\n"
    summary += f"# Feature ID: {feature_idx}\n"
    summary += f"# Total Activations Analyzed: {total_activations}\n"
    summary += f"# Unique Tokens: {len(token_stats)}\n"
    summary += "#\n"

    final_output = summary + output.getvalue()

    # Save and download
    if output_filename is None:
        output_filename = f"feature_{feature_idx}_tokens.csv"

    with open(output_filename, 'w') as f:
        f.write(final_output)

    print(f"\nSaved to {output_filename}")
    print(f"Top 10 most frequent tokens for feature {feature_idx}:")
    for row in csv_data[:10]:
        print(f"  '{row['token_string']}' (ID {row['token_id']}): {row['count']} times, avg={row['average_activation']:.4f}")

    # Download the file
    files.download(output_filename)

    return csv_data

# Example usage:
"""
results = analyze_feature_to_tokens_csv(
    feature_idx=16751,  # The emphatic complaint feature from your examples
    h5_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_samples=50000,
    output_filename="feature_16751_token_analysis.csv"
)
"""

"""## 3.4 Usage Examples

### 3.4.1. Feature 16751
 Emphatic Complaint Formulas with Weak Discourse Marker Detection
This feature exhibits asymmetric polysemanticity, primarily detecting emphatic negative and interrogative constructions in restaurant reviews, with much weaker sensitivity to neutral prepositional discourse markers.
Pattern 1: Emphatic Complaint Formulas (Strong Activation: 0.05-0.17)
The feature strongly activates on interrogative or negative words followed by prepositional phrases, particularly "in the/my" constructions. This pattern shows remarkable flexibility:
Interrogative variants (all interrogatives work):

"why in the world" (0.139 + 0.118)
"what in the hell" (0.129 + 0.063)
"how in the world" (0.084 + 0.088)
"where/when/who/which in the [noun]" (0.043-0.067)

Negative variants:

"never in my life" (0.119 + 0.101)
"nothing in the world/universe" (0.068 + 0.061)
"not once in my life" (0.097 + 0.107)
"nobody/nowhere/no one in the [noun]" (0.029-0.055)

Religious/emphatic intensifiers (highest activations):

"what in god's name" (0.125 + 0.139 + 0.102)
"how in heaven's name" (0.085 + 0.063 + 0.055)
"why on god's green earth" (0.047 + 0.067 + 0.068)
"how in anyone's right mind" (0.096 + 0.106 + 0.065)

Flexible constructions:

Articles often optional: "why in hell" (0.067) vs "why in the hell"
Possessives flexible: "never in life" (0.100) vs "never in my life"
Complex word orders work: "never have I ever in my entire life" (0.167 + 0.103 + 0.118)
Discourse markers enhance: "seriously, why in the world" (0.122), "literally never in my life" (0.107)

Pattern 2: Prepositional Discourse Markers (Weak Activation: 0.02-0.06)
Despite appearing frequently in training data, these patterns rarely activate in isolation:
Opinion markers: "in my opinion" (423 occurrences in training, but typically 0.019-0.045 activation)
Temporal markers: "by the time" (177 occurrences, 0.025-0.035 when activating)
Evaluative markers: "in the way of" (0.037-0.062)
Location markers: "in the area" (187 occurrences, rarely activates)
Conclusion markers: "in the end" (0.021-0.024)
These Pattern 2 phrases generally only activate when:

Preceded by negatives: "not much in the way of" (0.037)
Following Pattern 1 triggers: "why would anyone in the area" (0.036)

Activation Asymmetry
The feature shows a 10x activation difference between patterns despite Pattern 2 being 6x more frequent in training data:

Pattern 1 (emphatic): ~70 training examples ‚Üí 0.05-0.17 activation
Pattern 2 (discourse): ~400+ training examples ‚Üí 0.02-0.06 activation (often none)

#### 3.4.1.1. Looking at SAE Activations file and examining activation patterns for feature 16751
"""

# Test with a feature
test_feature = 16751  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

"""#### 3.4.1.2. Matching first review from 3.4.1. with local activations

The idea here is to pull the review text and run it back through our pipeline to see whether our activations match.
"""

#You can use this to match activations
review_text = get_review_text('mSWe3_9hctHiahBB4Du3OQ', metadata_df)
print(review_text)


feature_idx = [16751]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""#### 3.4.1.3 Looking at activation context patterns
The transformer residual streams only include information from tokens in the context that come BEFORE the token of interest. One way of looking at the impact of context is to remove tokens one at a time from the front of a piece of text and see how that impacts activations. See example below.

"""

word_removal_array=create_word_removal_array("Worst tacos in the world")

feature_idx = [16751]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

"""#### 3.4.1.4 Create Comprehensive Report for Feature

Warning, this can be slow - to reduce processing time, reduce max samples. 1000 is relatively quick.
"""

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=16751,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""#### 3.4.1.5. Probes"""

phrases  = test_phrases_pattern1_extended = [
    # Other interrogatives + "in the/my"
    "who in the world thought this was acceptable",          # 'who' interrogative
    "where in the hell did they find this chef",            # 'where' interrogative
    "when in the world did service become optional",         # 'when' interrogative
    "which in the name of god is the real menu",            # 'which' + religious emphasis

    # Extended negative variations
    "not once in my life have I been so insulted",          # 'not once'
    "nobody in the world would call this edible",           # 'nobody'
    "no one in the area should waste money here",           # 'no one'
    "not a soul in the place seemed to care",               # 'not a soul'
    "nothing in the universe could make me return",         # extreme scope

    # Alternative emphatic expressions
    "why on god's green earth would anyone eat this",       # religious emphasis
    "what in tarnation were they thinking",                 # folksy emphasis
    "how in heaven's name do they stay open",               # religious variant
    "where in creation did they learn to cook",             # creation emphasis

    # Testing scope/scale words
    "never in the history of dining have I seen",           # 'history'
    "nowhere in the entire city serves worse",              # 'entire city'
    "nothing in all my years prepared me for this",         # 'all my years'
    "why in the whole wide world would they",               # 'whole wide world'

    # Testing without "the/my"
    "why in hell would anyone recommend this",              # no article
    "never in life will I return here",                     # no possessive
    "what in god's name is this supposed to be",           # possessive 's
    "how in anyone's right mind is this five stars",       # different possessive

    # Complex variations
    "never in a million years would I have believed",       # 'in a million'
    "not in this lifetime will I come back",               # 'in this lifetime'
    "nowhere in all of creation is food this bad",         # multiple emphatics
    "why in the name of all that is holy",                 # extended religious

    # Boundary testing
    "seriously, why in the world",                          # intro word
    "I mean why in the hell would they",                   # filler phrase
    "like how in the world is this possible",              # informal starter
    "literally never in my life seen worse",               # intensifier
]
feature_idx = [16751]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""### 3.4.2. Feature 23016

#### 3.4.2.1. Looking at SAE Activations file and examining activation patterns for feature 16751
"""

feature = 23016
# Test with a feature
test_feature = feature  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

"""#### 3.4.2.2. Matching first review from 3.4.1. with local activations

The idea here is to pull the review text and run it back through our pipeline to see whether our activations match.
"""

#You can use this to match activations
review_text = get_review_text('4RN49iQhDevmBKhrSPmy7w', metadata_df)
print(review_text)


feature_idx = [feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""#### 3.4.2.3 Looking at activation context patterns
The transformer residual streams only include information from tokens in the context that come BEFORE the token of interest. One way of looking at the impact of context is to remove tokens one at a time from the front of a piece of text and see how that impacts activations. See example below.

"""

word_removal_array=create_word_removal_array("Great little Taco joint near the Barnes Museum. $3.50 for 2 tacos.")

feature_idx = [feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

"""#### 3.4.2.4 Create Comprehensive Report for Feature

Warning, this can be slow - to reduce processing time, reduce max samples.
"""

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=1000
)

"""### 3.4.3. Feature 20379: Token Detector for "Gum" as in "Gumbo"

Note that this is a token that activates very rarely.

This is a lexical feature detector that is not very context sensitive. It applies to "gum" in gumbo, "cav" in caviar, "chewing" as in "chewing gum", "Horn" as in Hornitos Tequila, and "pad" as in pad Thai

#### 3.4.3.1. Looking at SAE Activations file and examining activation patterns
"""

# Test with a feature
test_feature = 20379  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

"""#### 3.4.3.2. Matching first review from 3.4.1. with local activations

The idea here is to pull the review text and run it back through our pipeline to see whether our activations match.
"""

#You can use this to match activations
review_text = get_review_text('7bv7byBskPPtspS8iUHzmA', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""#### 3.4.3.3 Looking at activation context patterns
The transformer residual streams only include information from tokens in the context that come BEFORE the token of interest. One way of looking at the impact of context is to remove tokens one at a time from the front of a piece of text and see how that impacts activations. See example below.

"""

word_removal_array=create_word_removal_array("I love gum drops and gumbo")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

"""#### 3.4.3.4 Create Comprehensive Report for Feature

Warning, this can be slow - to reduce processing time, reduce max samples. 1000 is relatively quick.
"""

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""#### 3.4.3.5. Probes"""

phrases  = [
    # Hypothesis 1: Foods with Distinctive Textures (10 examples)
    "The restaurant's gumbo was perfectly thick and hearty",
    "Fresh caviar burst on my tongue with each bite",
    "Their pad Thai had the perfect chewy noodle texture",
    "I was chewing gum throughout the entire meeting",
    "The tapioca pearls in the bubble tea were wonderfully chewy",
    "That mochi had such a unique sticky texture",
    "The risotto achieved the perfect creamy consistency",
    "Their polenta was silky smooth",
    "The flan had a perfectly jiggly texture",
    "Those gummy bears were incredibly chewy",

    # Hypothesis 2: Restaurant Specialty Items (10 examples)
    "Their signature gumbo is what put them on the map",
    "The caviar service here is absolutely exquisite",
    "Best pad Thai in the city, hands down",
    "Don't miss their craft libations menu",
    "They're famous for their seafood gumbo",
    "The Mexican gumbo fusion dish is their specialty",
    "Premium Hornitos tequila selection available",
    "Their cowboy caviar appetizer is a must-try",
    "The chef's special gumbo won several awards",
    "House-made chewing gum as a palate cleanser",

    # Hypothesis 3: Viscous/Sticky Consumables (10 examples)
    "Thick gumbo coating the spoon",
    "Caviar pearls popping between teeth",
    "Sticky pad Thai sauce clinging to noodles",
    "Chewing gum stuck to my shoe",
    "The Horn cocktail had a syrupy consistency",
    "Viscous libations poured slowly",
    "That gummy candy was impossibly sticky",
    "The thick gumbo barely dripped off the ladle",
    "Caviar eggs bursting with briny liquid",
    "Chewy caramel stuck to my teeth",

    # Non-activating examples (10 examples)
    "The salad was fresh and crispy",
    "I prefer my steak medium-rare",
    "The weather was beautiful yesterday",
    "She studied computer science in college",
    "The car needs an oil change",
    "Books lined the library shelves",
    "The meeting starts at 3 PM",
    "Exercise is important for health",
    "The blue sky stretched endlessly",
    "Mathematics requires logical thinking"
]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])



"""### 3.4.3. Feature 14292: Demonstrative-Initiated Descriptive Phrase Detector

## Overview
This feature activates on syntactic patterns where demonstrative determiners (This/That/Such) introduce descriptive or categorizing phrases. It is purely syntactic and agnostic to semantic content. You might say that this points to a kind of specificity in reviews. You have to directly point at something as opposed to being handwavy.

## Primary Activation Patterns

### Pattern 1: Demonstrative + Adjective
- **Structure**: `This/That + [adjective] + [noun]`
- **Activation Range**: 0.091-0.124
- **Examples**:
  - "This wonderful bakery" (0.116)
  - "That terrible storm" (0.117)
  - "This exact model" (0.117)

### Pattern 2: Such + Article + Adjective  
- **Structure**: `Such + a/an + [adjective] + [noun]`
- **Activation Range**: 0.085-0.094 (combined)
- **Examples**:
  - "Such a wonderful place" (0.078 + 0.094)
  - "Such a terrible waste" (0.085 + 0.082)

### Pattern 3: Demonstrative + Categorization
- **Structure**: `This/That + [type/kind/sort/variety] + of`
- **Activation Range**: 0.070-0.161 (combined)
- **Examples**:
  - "This type of" (0.018 + 0.073)
  - "That sort of" (0.085 + 0.070)
  - "This variety of" (0.057 + 0.102)

## Key Characteristics
- **No activation** for adjectives without demonstratives (e.g., "wonderful weather" = 0)
- **No activation** for other determiners (the/a/an/my/her)
- **Weak activation** (~0.030) for "Some + [strong evaluative adjective]"
- **Domain**: Commonly appears in reviews and evaluative text
- **Function**: Marks proximal/distal deixis with simultaneous evaluation or categorization

## Non-Activating Examples
- "Amazing performance" ‚ùå
- "The terrible service" ‚ùå  
- "A wonderful place" ‚ùå
- "Her particular style" ‚ùå

#### 3.4.3.1. Looking at SAE Activations file and examining activation patterns
"""

# Test with a feature
test_feature = 14292  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

"""#### 3.4.3.2. Matching first review from 3.4.1. with local activations

The idea here is to pull the review text and run it back through our pipeline to see whether our activations match.
"""

#You can use this to match activations
review_text = get_review_text('VfmlcneTcPpDy93GAROEqw', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""#### 3.4.3.3 Looking at activation context patterns
The transformer residual streams only include information from tokens in the context that come BEFORE the token of interest. One way of looking at the impact of context is to remove tokens one at a time from the front of a piece of text and see how that impacts activations. See example below.

"""

word_removal_array=create_word_removal_array("I love gum drops and gumbo")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

"""#### 3.4.3.4 Create Comprehensive Report for Feature

Warning, this can be slow - to reduce processing time, reduce max samples. 1000 is relatively quick.
"""

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""#### 3.4.3.5. Probes"""

phrases  = [
    # 1. Specificity and Concrete Reference
    "This amazing pasta dish had perfectly al dente noodles.",
    "That rude waiter completely ignored our table.",
    "This particular menu item was overpriced for the portion.",
    "That incredible view made the whole experience worthwhile.",

    # 2. Natural Story-Telling and Scene-Setting
    "We walked into this little cafe hidden behind the bookstore.",
    "They serve this incredible chocolate dessert that melts perfectly.",
    "We found this charming spot tucked away in the alley.",
    "You enter through this narrow doorway that opens into a grand hall.",

    # 3. Implicit Comparison and Context
    "This particular location has much better service than others.",
    "That type of service is rare in this neighborhood.",
    "This specific branch maintains higher standards.",
    "That kind of attention to detail sets them apart.",

    # 4. Categorical Organization
    "This kind of restaurant is perfect for date nights.",
    "That type of atmosphere appeals to young professionals.",
    "This sort of establishment knows its target audience.",
    "That variety of cuisine is hard to find locally.",

    # 5. Emphasis and Memorability
    "That awful smell in the bathroom ruined our appetite.",
    "This amazing view from the terrace is unforgettable.",
    "That terrible noise from the kitchen was constant.",
    "This perfect temperature for the wine impressed me.",

    # 6. Reduced Cognitive Load (referential anchors)
    "This place serves great coffee. This same place also has WiFi.",
    "That dish was spicy. That exact spiciness overwhelmed other flavors.",
    "This location opened recently. This new spot already has regulars.",
    "That server was helpful. That wonderful attitude made our day.",

    # Control: Vague, less helpful review language (shouldn't activate)
    "Food was good and service was fine.",
    "Everything tasted fresh and delicious.",
    "Nice ambiance and reasonable prices.",
    "Would recommend to anyone looking for Italian.",
    "Great experience overall with minor issues.",
    "Excellent quality and generous portions."
]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""# NEW!! Feature 11328 - Noun lists where items are separated by line breaks.  (8/18/2025) The activations get stronger as lists get longer."""

# Test with a feature
test_feature = 11328  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=100_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=100000
)

review_text = get_review_text('IBlIsyxwzVOZZIToHFQpUA', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

phrases = ["""Here's what you should order:
- smoked salmon sopes
- quarter roast chicken
- quarter roast pork
- roasted cauliflower
- roasted carrots
- CHURROS!

That's what we ordered,""",
"""Here's what I liked:
Avocados
Tomatos
Potatos
Cheese
But nothing else""",
"""I enjoyed this meal because I thought that everything in it was highly delicious.
The cheese was tasty and the avocados were fresh.
What I didn't like was the appetizers. overpricecd.
They didn't seem to have the same quality as the rest of the dishes. I also really didn't like the taste of the smoked salmon appetizer
I'd highly recommend staying for dessert. Their fried ice cream is to die for and it comes in lots of different and unusual flavors. For example:
Avocados
Tomatos
Potatos
Cheese""",
"""I enjoyed this meal
Avocados
B
C
Tomatos
Potatos
Cheese
A big bunch of green Onions
Pimento
Beer
Noodles
Tortillas""",
"""Avocados
Enjoyment
Pianos
Apples
""",
"""Trees
Avocados
Enjoyment
Apples
Pianos
""",
"""Seeds
Avocados
Enjoyment
Apples
Pianos
""",
"""Seeds
Avocados
Enjoyment
Pianos
Apples
""",
"""Seeds
Avocados
Bananas
Pianos
Apples
""",
"""Seeds
Avocados
Bananas
Tacos
Pianos
Apples
""",
"""Seeds
Avocados
Bananas
Tacos
Beef
Pianos
Apples
"""
]


feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

phrases = ["""This spot was amazing! The service was fast and everything came out hot and fresh. We ordered:
- Tacos al pastor
- Guacamole
- Churros.
Each dish was delicious and felt homemade. Highly recommended!""",
"""Great dinner last night. The portions are generous and the menu is creative. Here‚Äôs what we tried:
1. Shrimp ceviche
2. Chicken enchiladas
3. Mango margarita.
All three items were excellent, but the ceviche was the star.""",
"""Honestly one of the best brunches I‚Äôve had in a while. What we ordered:
- Pancakes
- Avocado toast
- Cappuccino.
Everything came out quickly and was perfectly prepared.""",
"""This is my go-to sushi spot. Last visit I had:
- Salmon nigiri
- Spicy tuna roll
- Miso soup.
The fish was so fresh and flavorful, and the service was excellent.""",
"""Dinner for two and everything was spot on. Our order:
1) Caesar salad
2) Ribeye steak
3) Chocolate lava cake.
All three courses were perfect, especially the steak cooked medium rare.""",
"""Had a fun night out with friends! Here‚Äôs what we shared:
- Loaded nachos
- Queso dip
- Street corn.
Everything was tasty and the drinks were strong.""",
"""The bakery is fantastic. This morning I picked up:
1. Croissant
2. Blueberry muffin
3. Latte.
All were fresh and flavorful‚Äîthe croissant was buttery perfection.""",
"""Celebrated my birthday here! The highlights:
- Bruschetta
- Lobster ravioli
- Tiramisu.
The staff even brought out a candle with dessert, which made it extra special.""",
"""Such a cozy caf√©. What we enjoyed:
1) Flat white
2) Almond croissant
3) Quiche Lorraine.
The croissant was warm and flaky, and the coffee was smooth and bold.""",
"""Stopped by for lunch and loved it. My picks:
- BBQ chicken sandwich
- Sweet potato fries
- Iced tea.
The sandwich was tender and flavorful, and the fries were perfectly crispy."""
]


feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

phrases = [
    """This place was amazing!

The atmosphere really stood out to me.""",

    """Went here for dinner.
Not what I expected at all.""",

    """The food was cold when it arrived...

Won't be coming back.""",

    """Beautiful restaurant!

However, the service needs work.""",

    """My favorite spot in town.


Definitely recommend the pasta.""",

    """Overpriced and underwhelming.
The decor was nice though.""",

    """First time visiting‚Äî

what a disappointment.""",

    """Great cocktails!



Terrible food though.""",

    """The waiter was rude.

Manager didn't care when we complained.""",

    """Love this place so much!

It's become our regular date night spot."""
]

phrases = [
    """The ambiance was absolutely stunning with dim lighting and jazz music.

The appetizers were beautifully plated but underwhelming in flavor.

By the time our entrees arrived, we had been waiting over an hour.""",

    """I've been coming here for three years and the quality keeps declining.

Yesterday they were out of half the menu at lunch time.

Despite these issues, the location and prices keep me coming back.""",

    """This place feels like a 1950s diner with checkered floors and red booths.

Their famous triple-stack burger lived up to all the hype.

The only downside is the 45-minute wait on weekends.""",

    """This fusion restaurant opened two months ago and it's already packed.

The kimchi quesadilla sounds weird but works brilliantly.

Service was impeccable with knowledgeable staff throughout.""",

    """High expectations for this Michelin-starred birthday dinner at $200 per person.

Beautiful Instagram-worthy plates that unfortunately didn't taste as good as they looked.

The dessert course and wine pairings saved the evening.""",

    """The rooftop location offers unbeatable panoramic city views.

Unfortunately the food was remarkably average for premium prices.

The cocktails were excellent though - creative and well-balanced.""",

    """This family-owned trattoria genuinely transported me back to Rome.

Fresh pasta with perfect texture and authentic wood-fired pizza.

Surprisingly reasonable prices given the quality and portions.""",

    """Two-hour wait on Sunday should have been our first warning.

When food finally arrived, it was cold and undercooked.

They comped our meal but I'd rather have paid for good food.""",

    """Finally got a reservation at this celebrity chef's new place.

Good food but not the life-changing experience the hype suggests.

Worth trying once if someone else is paying.""",

    """Hidden gem in Chinatown with the most authentic Sichuan food.

The mapo tofu had perfect numbing spice that makes your mouth tingle.

Fair warning: when they say spicy, they really mean it."""
]

phrases=[
    """The service was incredibly slow tonight.
We waited two hours for our entrees.
The appetizers were cold.
Our water glasses stayed empty.
Never coming back here.""",

    """Loved the outdoor seating area.
String lights created perfect ambiance.
Cocktails were expertly crafted.
Food came out quickly.
Prices were surprisingly reasonable.""",

    """This place used to be great but the new management ruined everything.
Menu has been completely gutted.
Quality went way down.
Even the regulars are leaving.""",

    """Reservation system is a joke.
They gave away our table and made us wait another hour.
No apology from anyone.
Completely unprofessional operation.""",

    """The noise level was unbearable.
Music was way too loud and I couldn't hear my date.
They refused to turn it down.
We left before ordering.""",

    """First time trying Ethiopian food.
Eating with hands felt strange.
Flavors were too intense and spice level was extreme.
Will stick to Italian.""",

    """Birthday dinner was a disaster.
Steak was completely overcooked.
Sides were ice cold.
They forgot the cake.
At least they comped it.""",

    """The view makes everything better.
Panoramic city skyline views. A Perfect sunset spot.
Food doesn't really matter.
Worth it for photos alone.""",

    """Portions are absolutely tiny.
Three tacos for thirty dollars.
Salad was just lettuce.
Left still feeling hungry. Complete waste of money.""",

    """Cash only in 2024.
No warning on website.
ATM was broken too.
They wouldn't hold table."""
]

phrases=[
    """Just had dinner at Marino's and wanted to share what makes this place special:
- Fresh seafood flown in daily from Maine
- Wine selection with over 300 bottles
- Live jazz every Friday and Saturday
- Beautiful heated patio overlooking the river
- Free valet parking which is rare downtown
Overall, definitely worth the premium prices.""",

    """The new tasting menu was incredible tonight.
1. Amuse-bouche with caviar
2. Butternut squash soup
3. Seared scallops
4. Wagyu beef tenderloin
5. Lemon souffl√©
Each course was perfectly timed and beautifully presented.""",

    """What really stood out at this place tonight was
Amazing cocktail program
Knowledgeable sommelier
Perfect ambiance for dates
Live piano music
Impeccable service throughout
Can't wait to return for another special occasion.""",

    """Our anniversary dinner was perfect. We had
* Grilled octopus to start
* Burrata and heirloom tomatoes
* Duck confit for her
* Lamb chops for me
* Shared tiramisu for dessert
Everything exceeded expectations except the lamb was slightly overdone.""",

    """This place has seriously declined.
- Bathroom needs renovation
- Menu needs updating
- Prices don't match quality
- Staff seems poorly trained
- Lighting is too bright
Used to love coming here but not anymore.""",

    """Their famous brunch spread includes
‚Üí Eggs Benedict
‚Üí French toast
‚Üí Crispy bacon
‚Üí Fresh fruit bowl
‚Üí Bottomless mimosas
The French toast was heavenly but eggs were cold.""",

    """Best new restaurant this year because of:
‚úì Farm-to-table ingredients
‚úì Creative seasonal menus
‚úì Accommodating allergies
‚úì Wine pairings
‚úì Presentation
Every single dish was spectacular.""",

    """Sunday dinner was a complete disaster.
First, they lost our reservation
Then seated us by the kitchen
Forgot two appetizers
Main courses took 90 minutes
Never got our dessert order
Management really needs to get it together.""",

    """Great venue for events. They offer
> Private dining rooms
> Full bar service
> Custom menu options
> AV equipment for presentations
> Dedicated event coordinator
Hosted our wedding rehearsal dinner here last month.""",

    """I always order the same thing here and it never disappoints.
Start with French onion soup
Follow with Caesar salad
Medium-rare filet mignon
Truffle mac and cheese side
Cr√®me br√ªl√©e to finish
Been getting this exact meal for three years straight."""
]

phrases=[
    """This place has everything:
Pizza
Pasta
Salad
Wine
Dessert
Perfect for families.""",

    """We tried:
Tacos
Nachos
Quesadilla
Great Mexican food!""",

    """Menu includes
Breakfast
Lunch
Dinner
Open all day which is convenient.""",

    """They offer:
Delivery
Takeout
Catering
Dine-in
Very flexible options.""",

    """Ordered
Burger
Fries
Shake
Classic American fare done right.""",

    """Available cuisines:
Thai
Chinese
Japanese
Korean
Best Asian fusion in town.""",

    """Bar serves
Cold Beer
Crisp Cocktails
Red and white wine
Happy hour 4-6pm daily.""",

    """Kids menu has
Chicken fingers
Mac and cheese
Hot dog
Pizza
Grilled cheese
All under $8.""",

    """Desserts tonight
Cheesecake
Ice cream
Pie
Too full to try any.""",

    """Specials today:
Soup
Fish
Pasta
All looked amazing."""
]

phrasesX=[
    """Just had dinner at Marino's and wanted to share what makes this place special:
- Fresh seafood flown in daily from Maine
- Wine selection with over 300 bottles
- Live jazz every Friday and Saturday
- Beautiful heated patio overlooking the river
- Free valet parking which is rare downtown
Overall, definitely worth the premium prices.""",

    """The new tasting menu was incredible tonight.
1. Amuse-bouche with caviar
2. Butternut squash soup
3. Seared scallops
4. Wagyu beef tenderloin
5. Lemon souffl√©
Each course was perfectly timed and beautifully presented.""",

    """What really stood out at this place tonight was
Amazing cocktail program
Knowledgeable sommelier
Perfect ambiance for dates
Live piano music
Impeccable service throughout
Can't wait to return for another special occasion.""",

    """Our anniversary dinner was perfect. We had
* Grilled octopus to start
* Burrata and heirloom tomatoes
* Duck confit for her
* Lamb chops for me
* Shared tiramisu for dessert
Everything exceeded expectations except the lamb was slightly overdone.""",

    """This place has seriously declined.
- Bathroom needs renovation
- Menu needs updating
- Prices don't match quality
- Staff seems poorly trained
- Lighting is too bright
Used to love coming here but not anymore.""",

    """Their famous brunch spread includes
‚Üí Eggs Benedict
‚Üí French toast
‚Üí Crispy bacon
‚Üí Fresh fruit bowl
‚Üí Bottomless mimosas
The French toast was heavenly but eggs were cold.""",

    """Best new restaurant this year because of:
‚úì Farm-to-table ingredients
‚úì Creative seasonal menus
‚úì Accommodating allergies
‚úì Wine pairings
‚úì Presentation
Every single dish was spectacular.""",

    """Sunday dinner was a complete disaster.
First, they lost our reservation
Then seated us by the kitchen
Forgot two appetizers
Main courses took 90 minutes
Never got our dessert order
Management really needs to get it together.""",

    """Great venue for events. They offer
> Private dining rooms
> Full bar service
> Custom menu options
> AV equipment for presentations
> Dedicated event coordinator
Hosted our wedding rehearsal dinner here last month.""",

    """I always order the same thing here and it never disappoints.
Start with French onion soup
Follow with Caesar salad
Medium-rare filet mignon
Truffle mac and cheese side
Cr√®me br√ªl√©e to finish
Been getting this exact meal for three years straight."""
]



phrasesX = [
    # ORIGINAL ORDER
    """Great Italian restaurant offering:
Fresh pasta
Wood-fired pizza
Grilled seafood
Homemade gelato
Everything tastes authentic.""",

    # FLIPPED MIDDLE ITEMS
    """Great Italian restaurant offering:
Fresh pasta
Grilled seafood
Wood-fired pizza
Homemade gelato
Everything tastes authentic.""",

    # ORIGINAL ORDER
    """Problems with our visit:
Slow service
Cold food
Wrong orders
High prices
Won't return again.""",

    # FLIPPED MIDDLE ITEMS
    """Problems with our visit:
Slow service
Wrong orders
Cold food
High prices
Won't return again.""",

    # ORIGINAL ORDER
    """Weekend brunch includes:
Eggs Benedict
French toast
Avocado toast
Bottomless mimosas
Always packed Sundays.""",

    # FLIPPED MIDDLE ITEMS
    """Weekend brunch includes:
Eggs Benedict
Avocado toast
French toast
Bottomless mimosas
Always packed Sundays.""",

    # ORIGINAL ORDER
    """The chef specializes in:
Sushi rolls
Ramen bowls
Tempura dishes
Sake pairings
Truly exceptional experience.""",

    # FLIPPED MIDDLE ITEMS
    """The chef specializes in:
Sushi rolls
Tempura dishes
Ramen bowls
Sake pairings
Truly exceptional experience.""",

    # ORIGINAL ORDER
    """Must-try items:
Lobster bisque
Caesar salad
Ribeye steak
Chocolate souffl√©
Worth the price.""",

    # FLIPPED MIDDLE ITEMS
    """Must-try items:
Lobster bisque
Ribeye steak
Caesar salad
Chocolate souffl√©
Worth the price."""
]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("""I enjoyed this meal
           Avocados
           Blue
           Che
           Tomatos
           Potatos
           Cheese
           A big bunch of green Onions
           Pimento
           Beer
           Noodles
           Tortillas""")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

"""# NEW!! Feature 10998 Directive language with "Your" (8/18/2025)

So it activates "Burn your steak" but not "They'll burn your steak"

So for example "Save your money! They'll burn your steak" activates strongly on the first "your" but not the second. But it will activate with "Burn your steak"
"""

# Test with a feature
test_feature = 10998  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

review_text = get_review_text('qXwme4CnrbBfslfKO5k2Jg', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

phrases =  [
    # Direct commands in reviews
    "Save your money",  # original (0.092)
    "Skip your dessert",
    "Avoid your usual order",
    "Bring your own wine",
    "Request your steak well-done",

    # Softened restaurant advice
    "You should save your appetite",
    "Try to get your reservation early",
    "Remember to check your bill",
    "Don't forget to tip your server",
    "Be sure to make your reservation",

    # Indirect restaurant warnings
    "Consider saving your money",
    "You might want to skip your visit",
    "I'd suggest checking your receipt",
    "Perhaps bring your kids elsewhere",
    "Maybe reconsider your plans",

    # Non-directive restaurant statements
    "They ruined your meal",
    "The chef prepared your steak perfectly",
    "Your server was attentive",
    "We enjoyed your recommendation",
    "Your table wasn't ready",
]
feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

phrases =  [
    "We went to La Brisa last Saturday for a casual dinner. The decor is cozy and the staff were friendly. Save your money ‚Äî don't bother coming. Our tacos were bland and overpriced, though the margaritas were decent. Overall, not worth the trip from my neighborhood.",
    "I had high hopes for the new pastry shop on 3rd. The croissants were flaky and the espresso was solid. Skip your dessert ‚Äî the chocolate tart was dry and over-sweetened. The seating is limited, so it's better for takeout. All in all, a pleasant stop if you're in the mood for coffee and pastry.",
    "Dinner at the tapas bar was lively and well-priced. Service was attentive even though the place was busy. Bring your own wine ‚Äî they don't have a liquor license yet. The paella was the highlight, though the patatas bravas were a little greasy. I'll probably come back when friends are in town.",
    "We tried to celebrate my birthday at the Italian place, but it was packed. The host gave us an estimate of 45 minutes for a table. Try to get your reservation early ‚Äî they fill up weeks in advance. We ended up going to a nearby pub instead. The food sounded great, but next time we'll book well ahead.",
    "The diner had a warm, family atmosphere and a menu full of homestyle dishes. Our server was patient with our kids. Perhaps bring your kids elsewhere ‚Äî there is not much for them here. The kids' menu options are limited and a bit overpriced. It's fine for a quick breakfast but nothing special.",
    "We visited for lunch and had high expectations based on the reviews. The burgers smelled great but took forever to arrive. Save your time ‚Äî the slow service ruins the experience. When the food finally came, it was lukewarm and under-seasoned. The manager apologized and offered a discount, but I left frustrated.",
    "The family-style restaurant serves huge platters intended for sharing. We ordered two entrees and still had leftovers. Bring your appetite ‚Äî everything is huge and meant to be shared. If you love large portions and bold flavors, this will be your kind of place. It's lively and great for groups.",
    "We went on a Saturday night expecting a fun crowd. The line snaked out the door and the host said the wait was at least an hour. Don't make your reservation for Saturday ‚Äî the wait is ridiculous and the service suffers. After waiting 50 minutes we got a small table near the kitchen. The food was fine, but the whole evening felt rushed.",
    "The steakhouse has a polished atmosphere and a respectable wine list. We ordered the ribeye and a side of creamed spinach. Save your money and skip the pricier steaks ‚Äî they aren't worth the markup. Overall, I expected better given the price point. The sides were decent but not remarkable.",
    "We tried the new communal dining spot downtown and the concept is fun. Plates arrive family-style and are meant to be passed around. Bring your own plates if you plan to share ‚Äî the portions come family-style and toppings spill everywhere. It's an energetic place perfect for celebrating with friends. Make a reservation on weekends.",

    # without feature
    "We went to La Brisa last Saturday for a casual dinner. The decor is cozy and the staff were friendly. I wouldn't spend my money here. Our tacos were bland and overpriced, though the margaritas were decent. Overall, not worth the trip from my neighborhood.",
    "I had high hopes for the new pastry shop on 3rd. The croissants were flaky and the espresso was solid. I wouldn't order the chocolate tart; it was dry and over-sweetened. The seating is limited, so it's better for takeout. All in all, a pleasant stop if you're in the mood for coffee and pastry.",
    "Dinner at the tapas bar was lively and well-priced. Service was attentive even though the place was busy. They don't have a liquor license yet, so we brought a bottle. The paella was the highlight, though the patatas bravas were a little greasy. I'll probably come back when friends are in town.",
    "We tried to celebrate my birthday at the Italian place, but it was packed. The host gave us an estimate of 45 minutes for a table. Reservations fill up weeks in advance, so book early. We ended up going to a nearby pub instead. The food sounded great, but next time we'll book well ahead.",
    "The diner had a warm, family atmosphere and a menu full of homestyle dishes. Our server was patient with our kids. This isn't the best place for kids; there aren't many child-friendly options here. The kids' menu options are limited and a bit overpriced. It's fine for a quick breakfast but nothing special.",
    "We visited for lunch and had high expectations based on the reviews. The burgers smelled great but took forever to arrive. The slow service really ruined the experience for me. When the food finally came, it was lukewarm and under-seasoned. The manager apologized and offered a discount, but I left frustrated.",
    "The family-style restaurant serves huge platters intended for sharing. We ordered two entrees and still had leftovers. Come hungry ‚Äî everything is huge and meant to be shared. If you love large portions and bold flavors, this will be your kind of place. It's lively and great for groups.",
    "We went on a Saturday night expecting a fun crowd. The line snaked out the door and the host said the wait was at least an hour. Avoid Saturday nights ‚Äî the wait is ridiculous and the service suffers. After waiting 50 minutes we got a small table near the kitchen. The food was fine, but the whole evening felt rushed.",
    "The steakhouse has a polished atmosphere and a respectable wine list. We ordered the ribeye and a side of creamed spinach. I wouldn't recommend the pricier steaks; they aren't worth the markup. Overall, I expected better given the price point. The sides were decent but not remarkable.",
    "We tried the new communal dining spot downtown and the concept is fun. Plates arrive family-style and are meant to be passed around. The portions come family-style and toppings spill everywhere, so bring extra napkins and utensils. It's an energetic place perfect for celebrating with friends. Make a reservation on weekends."
]
feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("Save your money! They'll burn your steak")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

"""# NEW!! Feature 22080 This, that, or it after all forms of the word "Give" (8/19/2025)

This is typically used in phrases like "I'll give it a try" and "I've given it 5 stars" but it also misfires in words that end in give like "I forgave it"

However, it also activates on a variety of other verbs preceeding it like "Rate", "Assess", "Lend" but less strongly. And not all verbs. For example "refuse" does not activate.

In practice, though, this most frequently shows up in 2 types of phrases:

"I'll give it 5 stars"
and
"I'll give it a shot"
"""

# Test with a feature
test_feature = 22080  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

review_text = get_review_text('ZeaFQ46AkZWQl2ij2q7Mdw', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

phrases =  [
 # Testing more transfer/bestowal verbs
    "I offer it",
    "I hand it",
    "I pass it",
    "I lend it",
    "I send it",
    "I deliver it",

    # Testing allocation/assignment verbs
    "I allocate it",
    "I designate it",
    "I attribute it",
    "I credit it",

    # Testing withholding verbs
    "I deny it",
    "I refuse it",
    "I withhold it",

    # Testing receipt verbs
    "I receive it",
    "I accept it",
    "I get it",

    # Testing if it needs first person
    "They give it",
    "She grants it",
    "We award it",
    "You assign it",
]
feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("Save your money! They'll burn your steak")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

"""#NEW!! Feature 208 Final Analysis (Summary and Update Markers "UPDATE:") - (8/29/2025)"""

# Test with a feature
test_feature = 208
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=100_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

review_text = get_review_text('KcZ1UiR4v9nyJjMPP3OHLw', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=100000
)

phrases1 = [
    # Should activate (1-10)
    """Great food and service!

**UPDATE**: Went back last week and quality has declined.""",
    """The pasta was decent.

Update: Management reached out and offered a gift card.""",
    """Nice atmosphere but slow service.

EDIT: They've improved significantly since my last visit.""",
    """Food was cold when it arrived.

Edit: Owner contacted me to apologize.""",
    """Pretty standard fare.

*UPDATE*: Returning customer here - they've added new menu items!""",
    """Disappointing experience overall.

UPDATE 3/2024: Giving them another star after improvements.""",
    """Loved the ambiance!

Bonus: They have live music on Fridays now.""",
    """Service needs work.

ETA: Spoke with manager who promised training improvements.""",
    """Good but pricey.

Overall: Worth trying once but probably won't return regularly.""",
    """Decent lunch spot.

CONCLUSION: Better options available nearby for the price.""",

    """Great food and service!
**UPDATE**: Went back last week and quality has declined.""",
    """The pasta was decent.
Update: Management reached out and offered a gift card.""",
    """Nice atmosphere but slow service.
EDIT: They've improved significantly since my last visit.""",
    """Food was cold when it arrived.
Edit: Owner contacted me to apologize.""",
    """Pretty standard fare.
*UPDATE*: Returning customer here - they've added new menu items!""",
    """Disappointing experience overall.
UPDATE 3/2024: Giving them another star after improvements.""",
    """Loved the ambiance!
Bonus: They have live music on Fridays now.""",
    """Service needs work.
ETA: Spoke with manager who promised training improvements.""",
    """Good but pricey.
Overall: Worth trying once but probably won't return regularly.""",
    """Decent lunch spot.
CONCLUSION: Better options available nearby for the price.""",

    """Great food and service!**UPDATE**: Went back last week and quality has declined.""",
    """The pasta was decent. Update: Management reached out and offered a gift card.""",
    """Nice atmosphere but slow service. EDIT: They've improved significantly since my last visit.""",
    """Food was cold when it arrived. Edit: Owner contacted me to apologize.""",
    """Pretty standard fare. *UPDATE*: Returning customer here - they've added new menu items!""",
    """Disappointing experience overall. UPDATE 3/2024: Giving them another star after improvements.""",
    """Loved the ambiance! Bonus: They have live music on Fridays now.""",
    """Service needs work. ETA: Spoke with manager who promised training improvements.""",
    """Good but pricey. Overall: Worth trying once but probably won't return regularly.""",
    """Decent lunch spot. CONCLUSION: Better options available nearby for the price.""",

    # Should NOT activate (11-20)
    "I need to update my order - can I add a side of fries?",
    "The chef updates the menu seasonally which keeps things interesting.",
    """They update the menu seasonally which keeps things interesting.""",
    """Delicious food.
    They update the menu seasonally which keeps things interesting.""",
    "They edit their specials board daily based on fresh ingredients.",
    "Overall flavor profile was well-balanced with hints of rosemary.",
    "The bonus appetizer we ordered was surprisingly good.",
    "We concluded our meal with the chocolate souffle.",
    "Our ETA was 7pm but we arrived early and they seated us immediately.",
    "I'll edit my reservation if my plans change.",
    "The restaurant recently updated their interior decor.",
    "In conclusion to our appetizers, we ordered the seafood platter."
]

phrases2 = [
    # Variations on formatting and punctuation
    """Original review here.

UPDATE - They fixed everything!""",

    """Great pizza place.

***EDIT*** The owner responded to my concerns.""",

    """Decent sushi spot.

[UPDATE] New management has taken over.""",

    """Food was okay.

Update (March 2024): Much better now!""",

    # Other potential meta-commentary markers
    """Service was terrible.

REVISION: I was wrong, they were just busy that night.""",

    """Nice coffee shop.

ADDENDUM: They now have oat milk!""",

    """Mixed feelings initially.

FOLLOW-UP: Went back and loved it.""",

    """Standard burger joint.

PS: Their milkshakes are amazing though.""",

    """Good atmosphere.

BTW: They validate parking after 6pm.""",

    """Loved the tacos!

NOTE: Cash only, no cards accepted.""",

    # Time/date markers
    """Pretty good initially.

2024 UPDATE: Quality has gone downhill.""",

    """First visit was rough.

One month later: Completely transformed!""",

    # Multiple updates
    """Original review from 2023.

UPDATE 1: Better service now.

UPDATE 2: Menu expanded significantly.""",

    # Start of text variations
    """UPDATE: This is my third visit and it keeps getting better.

The food is consistently amazing.""",

    """Overall: Great experience but overpriced for what you get.""",

    # Single line break instead of double
    """Food was decent.
EDIT: They've improved the menu.""",

    # Other conclusion-type words
    """Nice dinner spot.

VERDICT: Worth the price for special occasions.""",

    """Tried their brunch menu.

FINAL THOUGHTS: Better lunch options elsewhere.""",

    """Visited twice this month.

IN SUMMARY: Inconsistent but has potential.""",

    """Long wait times unfortunately.

BOTTOM LINE: Food makes up for the wait."""
]

phrases3 = [
    # Testing 'Overall' - most frequent token
    """Great food and service!

Overall, I'd recommend this place.""",

    """Nice atmosphere here.

Overall: solid choice for lunch.""",

    """Mixed experience honestly.

Overall I think it's overpriced.""",

    # Testing 'Also' - second most frequent
    """Food was delicious!

Also, they have great cocktails.""",

    """Service was slow.

Also worth noting: cash only.""",

    # Testing 'Other' variations
    """Pizza was amazing!

Other than that, everything was perfect.""",

    """Great location downtown.

Otherwise, pretty average experience.""",

    # Testing 'Last/Lastly'
    """First, great ambiance.

Lastly, the dessert was incredible.""",

    """Appetizers were good.

Last point: parking is difficult.""",

    # Testing 'Bonus' - we know this activated at 0.126
    """Solid dinner spot.

Bonus points for the live music!""",

    """Food was excellent.

BONUS: Kids eat free on Tuesdays.""",

    # Testing 'Next' from frequency list
    """Visited last month.

Next time I'll try the pasta.""",

    # Testing 'Another' from frequency list
    """Good first impression.

Another thing: great wine selection.""",

    # Testing 'Recommend' variations
    """Nice casual spot.

Recommendation: try the fish tacos.""",

    """Service was attentive.

Would recommend for date night.""",

    # Testing 'ETA' which showed 0.120 activation
    """Waiting for table now.

ETA: 30 minutes they said.""",

    # Testing 'CONCLUS/Conclusion'
    """Tried multiple dishes.

CONCLUSION: overpriced but tasty.""",

    """Long review above.

In conclusion, worth one visit.""",

    # Testing 'Edited' variant
    """Posted this yesterday.

Edited: forgot to mention the great desserts!""",

    """Original review below.

*Edited to add: They contacted me to apologize.*"""
]

phrases4 = [
    "The tacos were mediocre at best.\n\nupdate: They've changed suppliers and everything tastes fresher now.",

    "Service was slow during lunch rush.\n\nupdated: Much better staffing on weekends makes a huge difference.",

    "Salad was wilted and dressing was bland.\n\nUpdating: New menu items are actually quite good.",

    "Coffee was burnt and bitter.\n\nedit: They've switched to a local roaster - much improved!",

    "Overpriced for the quality offered.\n\nedited: New management has adjusted pricing appropriately.",

    "Chicken was dry and underseasoned.\n\nEditing: Tried their fish instead - definitely the better choice.",

    "Long wait times even with reservation.\n\neta: They now use a better booking system that actually works.",

    "Desserts were too sweet and heavy.\n\nbonus: Their new pastry chef makes incredible lighter options.",

    "Cramped seating and noisy atmosphere.\n\nUpdates: They opened an upstairs section that's much more comfortable.",

    "Appetizers arrived cold.\n\nedits: Kitchen timing has improved dramatically since opening month."
]


feature_idx = [test_feature]
visualize_feature_activation(phrases1, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

test_feature = 208

results = analyze_feature_to_tokens_csv(
    feature_idx=test_feature,
    h5_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_samples=100000,
    output_filename="feature_208_token_analysis.csv"
)

"""# feature 7887

"""

# Test with a feature
test_feature = 7887  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

#You can use this to match activations
review_text = get_review_text('79MEI5blX1aplnhc7-BGtw', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("but our second vist? my god")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
    "The burger I had last night was absolutely incredible. Oh my god, the first bite practically melted in my mouth‚Äîit was juicy, flavorful, and perfectly cooked. The bun was soft yet sturdy enough to hold everything together, and the toppings were fresh. The fries on the side were hot and crispy, and the service was attentive without being overwhelming. I left completely satisfied and already planning my next visit.",
    "I stopped by this caf√© after work, and I‚Äôm so glad I did. Oh my gosh, the latte was the creamiest I‚Äôve ever had, with just the right balance of espresso and milk. The barista even created beautiful latte art that made the experience extra special. The space was cozy, with soft lighting and relaxing music in the background. I ended up staying longer than I planned, just soaking in the atmosphere. Highly recommended for coffee lovers.",
    "Dinner here was such a treat. Oh my, the pasta was so fresh and cooked to perfection, with a sauce that was rich and flavorful without being too heavy. The garlic bread was crispy on the outside and soft inside, perfect for dipping into the sauce. The staff checked in just the right amount of times, making sure we had everything we needed. The whole evening felt like a warm and welcoming experience, and I‚Äôll definitely be coming back.",
    "I attended a birthday dinner at this restaurant, and it was unforgettable. Oh my god, the steak was hands down one of the best I‚Äôve ever had‚Äîperfectly seared outside and tender inside. The sides were equally impressive, from the buttery mashed potatoes to the seasonal vegetables. The staff even surprised our table with a complimentary dessert to celebrate, which made the night even more special. A top-notch dining experience from start to finish.",
    "I walked into this bakery not expecting much, but I was blown away. Oh my goodness, the croissant was flaky, buttery, and warm, straight from the oven. It paired perfectly with a cappuccino that had just the right amount of foam. The interior of the bakery was charming, with the smell of fresh bread filling the air. The staff were cheerful and welcoming, which made the whole visit even better. I can‚Äôt wait to come back and try more pastries.",
    "We had brunch here over the weekend, and it was such a pleasant surprise. Oh my, the pancakes were fluffy and light, topped with fresh berries and just the right amount of syrup. The eggs were cooked exactly how I like them, and the bacon was crispy without being greasy. The atmosphere was lively but not too loud, making it a great place to catch up with friends. I‚Äôll definitely be adding this spot to my regular weekend routine.",
    "Our evening at this new bistro exceeded expectations. Oh my god, the appetizer alone could have been the highlight‚Äîit was beautifully plated and bursting with flavor. The main course continued to impress, and the dessert rounded out the meal perfectly. The service staff were attentive but never intrusive, and the d√©cor gave the space a warm, inviting feeling. It‚Äôs rare to find a place that gets every detail right, but this one truly did.",
    "I tried this little sushi spot on a whim, and I was so impressed. Oh my, the freshness of the fish was remarkable, and the rolls were crafted with so much care. The rice was seasoned just right, and every bite tasted clean and balanced. The chef clearly knows what they‚Äôre doing, and it showed in the presentation as well. The cozy environment made it feel like a hidden gem I can‚Äôt wait to return to.",
    "We booked a table here for an anniversary dinner, and it was worth every penny. Oh my gosh, the wine pairing with each course elevated the entire meal, and the flavors were unforgettable. The staff explained each dish with knowledge and enthusiasm, which added to the experience. The atmosphere was elegant but not pretentious, making it feel special without being stuffy. It‚Äôs the kind of place I‚Äôll be remembering for a long time.",
    "I wasn‚Äôt sure what to expect from this diner, but it quickly became a favorite. Oh my goodness, the milkshake was thick, creamy, and packed with flavor‚Äîit felt like a treat from a classic American diner. The burger was hearty, and the fries were golden and crisp. The staff were friendly and made sure everything was perfect throughout the meal. This place combines comfort food with great service, and I‚Äôll definitely be back.",

    # without feature
    "The burger I had last night was absolutely incredible. The first bite practically melted in my mouth‚Äîit was juicy, flavorful, and perfectly cooked. The bun was soft yet sturdy enough to hold everything together, and the toppings were fresh. The fries on the side were hot and crispy, and the service was attentive without being overwhelming. I left completely satisfied and already planning my next visit.",
    "I stopped by this caf√© after work, and I‚Äôm so glad I did. The latte was the creamiest I‚Äôve ever had, with just the right balance of espresso and milk. The barista even created beautiful latte art that made the experience extra special. The space was cozy, with soft lighting and relaxing music in the background. I ended up staying longer than I planned, just soaking in the atmosphere. Highly recommended for coffee lovers.",
    "Dinner here was such a treat. The pasta was so fresh and cooked to perfection, with a sauce that was rich and flavorful without being too heavy. The garlic bread was crispy on the outside and soft inside, perfect for dipping into the sauce. The staff checked in just the right amount of times, making sure we had everything we needed. The whole evening felt like a warm and welcoming experience, and I‚Äôll definitely be coming back.",
    "I attended a birthday dinner at this restaurant, and it was unforgettable. The steak was hands down one of the best I‚Äôve ever had‚Äîperfectly seared outside and tender inside. The sides were equally impressive, from the buttery mashed potatoes to the seasonal vegetables. The staff even surprised our table with a complimentary dessert to celebrate, which made the night even more special. A top-notch dining experience from start to finish.",
    "I walked into this bakery not expecting much, but I was blown away. The croissant was flaky, buttery, and warm, straight from the oven. It paired perfectly with a cappuccino that had just the right amount of foam. The interior of the bakery was charming, with the smell of fresh bread filling the air. The staff were cheerful and welcoming, which made the whole visit even better. I can‚Äôt wait to come back and try more pastries.",
    "We had brunch here over the weekend, and it was such a pleasant surprise. The pancakes were fluffy and light, topped with fresh berries and just the right amount of syrup. The eggs were cooked exactly how I like them, and the bacon was crispy without being greasy. The atmosphere was lively but not too loud, making it a great place to catch up with friends. I‚Äôll definitely be adding this spot to my regular weekend routine.",
    "Our evening at this new bistro exceeded expectations. The appetizer alone could have been the highlight‚Äîit was beautifully plated and bursting with flavor. The main course continued to impress, and the dessert rounded out the meal perfectly. The service staff were attentive but never intrusive, and the d√©cor gave the space a warm, inviting feeling. It‚Äôs rare to find a place that gets every detail right, but this one truly did.",
    "I tried this little sushi spot on a whim, and I was so impressed. The freshness of the fish was remarkable, and the rolls were crafted with so much care. The rice was seasoned just right, and every bite tasted clean and balanced. The chef clearly knows what they‚Äôre doing, and it showed in the presentation as well. The cozy environment made it feel like a hidden gem I can‚Äôt wait to return to.",
    "We booked a table here for an anniversary dinner, and it was worth every penny. The wine pairing with each course elevated the entire meal, and the flavors were unforgettable. The staff explained each dish with knowledge and enthusiasm, which added to the experience. The atmosphere was elegant but not pretentious, making it feel special without being stuffy. It‚Äôs the kind of place I‚Äôll be remembering for a long time.",
    "I wasn‚Äôt sure what to expect from this diner, but it quickly became a favorite. The milkshake was thick, creamy, and packed with flavor‚Äîit felt like a treat from a classic American diner. The burger was hearty, and the fries were golden and crisp. The staff were friendly and made sure everything was perfect throughout the meal. This place combines comfort food with great service, and I‚Äôll definitely be back."

]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""# feature 7907

"""

# Test with a feature
test_feature = 7907  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

#You can use this to match activations
review_text = get_review_text('9956sloUj4fMBAJA_BpVhA', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("This place has potential, and I'm glad to see them in the neighborhood")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 20276"""

# Test with a feature
test_feature = 20276  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

word_removal_array=create_word_removal_array("I came here for a Yelp event")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

#You can use this to match activations
review_text = get_review_text('ZjBUdvtI0evYJC4BARPH-g', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 5005

"""

# Test with a feature
test_feature = 5005  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

#You can use this to match activations
review_text = get_review_text('IEGZPZ2ipDIm_dfxK4CUXA', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("I would prefer that they get a bigger parking lot to park in-parking is horrible")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feautre 19056 (words having to do with ambiance)"""

# Test with a feature
test_feature = 19056  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

review_text = get_review_text('CPKt7YPISzRZvW2qhH9dUA', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("plus it 's a great **atmosphere** and very friendly staff")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

feature_idx=[19056]
phrases=[
    # 10 that should ACTIVATE - atmosphere/ambiance words
    "The restaurant has a wonderful atmosphere that makes you feel at home.",
    "We loved the cozy ambiance and dim lighting.",
    "Great food and fantastic atmosphere for date night.",
    "The ambience here is absolutely perfect.",
    "Such a relaxing atmosphere with live music.",
    "The environment feels upscale yet comfortable.",
    "Beautiful decor creates an elegant atmosphere.",
    "The vibe of this place is incredibly chill.",
    "Atmosphere: romantic and intimate.",
    "The overall ambiance really sets this place apart.",

    # 10 that should NOT activate - no atmosphere words
    "The food was delicious and service was quick.",
    "We ordered tacos, chips, and guacamole.",
    "Prices are reasonable for the portion sizes.",
    "The chicken was perfectly seasoned and tender.",
    "Located downtown near the theater district.",
    "They have an extensive wine selection.",
    "Our waiter was knowledgeable and friendly.",
    "The menu offers vegetarian and gluten-free options.",
    "Parking is available in the back lot.",
    "We made reservations for Saturday night.",

    # 10 edge cases and variations
    "The air conditioning was too cold.",  # 'air' but different context
    "The atmospheric pressure affects wine taste.",  # 'atmospheric' scientific context
    "The surrounding area is very busy.",  # 'surrounding' without 's'
    "The room had poor ventilation.",  # related to air but not atmosphere
    "Great ambient lighting throughout.",  # 'ambient' not 'ambiance'
    "The mood was festive and fun.",  # 'mood' instead of atmosphere
    "Nice surroundings and good food.",  # 'surroundings' which appeared in data
    "The setting is perfect for brunch.",  # 'setting' as atmosphere synonym
    "Loved the whole atmosphere here.",  # 'atmosphere' with 'here'
    "The decor adds to the experience.",  # 'decor' which was in top tokens
]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""# feature 11579 (Last name detector)

"""

# Test with a feature
test_feature = 11579  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

word_removal_array=create_word_removal_array("Aaron Sanchez is one of my favorite celebrity chef, and John Besh is one of my favorite local chef")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

feature_idx=[11579]
phrases=[
    # 10 that should ACTIVATE - First name + surname initial pattern
    "The restaurant is owned by Gordon R and his team.",
    "We met celebrity chef Bobby F at the opening.",
    "According to food critic Michael S, this place rocks.",
    "The new menu was designed by James B himself.",
    "I saw Anthony B filming here last week.",
    "Chef Wolfgang P created this signature dish.",
    "Restaurant owner Maria G was incredibly welcoming.",
    "Food Network's Alton B recommended this spot.",
    "The famous chef Emeril L has a restaurant nearby.",
    "Local celebrity chef Thomas K runs the kitchen.",

    # 10 that should NOT activate - No first name + initial pattern
    "The restaurant has excellent service and atmosphere.",
    "We ordered tacos, burritos, and quesadillas.",
    "The prices are reasonable for the quality.",
    "Located on Main Street near the shopping center.",
    "They serve authentic Mexican cuisine daily.",
    "The chicken was perfectly seasoned and cooked.",
    "Reservations are recommended on weekends.",
    "The atmosphere is casual but elegant.",
    "They have the best margaritas in town.",
    "Parking is available behind the building.",

    # 10 edge cases and variations
    "According to reviewer John, the food was amazing.",  # No surname initial
    "The place is owned by Mr. B and his family.",  # Title not first name
    "Chef Roberto prepared our meal perfectly.",  # Full name, no initial break
    "Jamie Oliver would love this place.",  # Full surname spelled out
    "Dr. Smith recommended this restaurant.",  # Title + surname
    "My friend David said it was good.",  # First name but no surname following
    "Owner J Martinez was very friendly.",  # Initial for first name
    "The chef's name is Robert.",  # Name at end of sentence
    "According to Sarah L from Yelp, it's great.",  # Should activate
    "Food blogger Jennifer C gave it five stars.",  # Should activate
]

visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

"""# feature 7191"""

# Test with a feature
test_feature = 7191  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

word_removal_array=create_word_removal_array("See photo for a peek")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

"""# feature 20598"""

# Test with a feature
test_feature = 20598  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 23933"""

# Test with a feature
test_feature = 23933  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 2597 (Checked AKM), 17588 (Checked AKM), 21756 (checked:"here"), 13627 (Checked AKM: Simple evaluative phrases about the restaurant - quite flexible and interesting!), 8134 (Checked AKM), 1893 (Checked AKM: "They have [determiner]" like "They have a nice patio" or "They have some outdoor seating"), 16686, 21422, 17273,"""

# Test with a feature
test_feature = 2597  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 17588  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 21756  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
    "I can't wait to come back here for their breakfast burritos and tacos.",
    "We're down here on business and stopped by ‚Äî such a great find here!",
    "Next time I'm looking for this dish, I'm definitely coming back here.",
    "I love meeting clients here for lunch; the chips and salsa are fantastic.",
    "I wouldn't go out of my way to come back here, but I did enjoy my meal.",
    "I'll surely be back here in the very near future.",
    "I should have gotten out of here when I had the chance.",
    "If you love queso, you'll be in heaven here ‚Äî it's bomb.",
    "I was certainly in a good mood being here.",
    "Nobody here wants to work ‚Äî the service was terrible tonight.",
    "Everything here is made from scratch and delicious.",
    "You can get authentic mole right here.",
    "We always bring out-of-town guests here because the food is reliable.",
    "Don't come here if you want quiet ‚Äî it's loud on weekends.",
    "I eat here at least once a month and never get tired of it.",
    "The manager fixed our mistake quickly here ‚Äî very impressed.",
    "The portions here are huge and worth the price.",
    "I won't be coming back here after that experience.",
    "Service here was slow, but the food more than made up for it.",
    "Hands down ‚Äî I go here for the margaritas every time.",
    "I can't wait to come back for their breakfast burritos and tacos.",
    "We're in town on business and stopped by ‚Äî such a great find!",
    "Next time I'm looking for this dish, I'll definitely return to this place.",
    "I love meeting clients at this restaurant for lunch; the chips and salsa are fantastic.",
    "I wouldn't go out of my way to return, but I did enjoy my meal.",
    "I'll be back in the very near future.",
    "I should have left when I had the chance.",
    "If you love queso, the queso at this spot is bomb.",
    "I was certainly in a good mood at the restaurant.",
    "Nobody at that location wants to work ‚Äî the service was terrible tonight.",
    "Everything at this place is made from scratch and delicious.",
    "You can get authentic mole at this restaurant.",
    "We always bring out-of-town guests to that spot because the food is reliable.",
    "Don't go to this place if you want quiet ‚Äî it's loud on weekends.",
    "I visit that restaurant at least once a month and never get tired of it.",
    "The manager fixed our mistake quickly at the venue ‚Äî very impressed.",
    "The portions at the restaurant are huge and worth the price.",
    "I won't be returning after that experience.",
    "Service was slow, but the food more than made up for it.",
    "Hands down ‚Äî I go to that bar for the margaritas every time."
]
feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 13627  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

test_feature = 13627  # We know this one is active

phrases  = [
    # Should activate (1-10) - positive food evaluation + punctuation
    "The food is great, but the service needs work.",
    "Food is amazing, simple as that.",
    "The food is good, not great but definitely worth trying.",
    "Food is excellent, and the portions are huge.",
    "The food is delicious, though a bit pricey.",
    "Food is fantastic, I'll definitely be back.",
    "The food is wonderful, especially the tacos.",
    "Food is great, atmosphere is great too.",
    "The food is good, cheap and fast.",
    "Food is solid, nothing to complain about.",

    # Should NOT activate (11-20) - different patterns
    "I think the food could be better.",
    "Their food needs improvement, honestly.",
    "We ordered food, drinks, and dessert.",
    "The restaurant serves Mexican food, Italian food, and sushi.",
    "Is the food good? Yes, very much so.",
    "Food was delivered quickly, still hot.",
    "Fast food, not fine dining.",
    "Comfort food, like mom used to make.",
    "The server asked if the food was okay, and it was.",
    "Ordered food, waited 45 minutes.",
    # Testing periods vs commas (no continuation)
    "The food is great.",
    "The food is good.",
    "The food is amazing.",
    "The food is excellent.",
    "The food is delicious.",

    # Testing other punctuation
    "The food is great!",
    "The food is good;",
    "The food is great -",
    "The food is wonderful:",
    "The food is fantastic...",

    # Testing if continuation matters
    "The food is great,",  # comma with no continuation
    "The food is good,",   # comma with no continuation

    # Testing exclamation points
    "The food is amazing!",
    "The food is incredible!",
    "The food is fantastic!",

    # Testing questions
    "The food is great?",
    "The food is good?",

    # Testing no punctuation at all
    "The food is great",
    "The food is good",
    "The food is excellent",
    # Standard construction we know works
    "The food is great.",

    # Varying the subject
    "Food is great.",
    "Their food is great.",
    "The meal is great.",
    "The pizza is great.",
    "The steak is great.",
    "The service is great.",
    "Everything is great.",

    # Varying the verb
    "The food was great.",
    "The food tastes great.",
    "The food looks great.",
    "The food seems great.",
    "The food feels great.",
    "The food sounds great.",

    # Different constructions
    "Food: great.",
    "Food = great.",
    "Food here is great.",
    "The food here is great.",
    "The food there is great.",

    # Inverted/different word orders
    "Great food.",
    "Food great.",
    "Is the food great.",
    "The great food.",
    "Food's great.",
    "The food's great.",

    # Multiple descriptors
    "The food is really great.",
    "The food is absolutely amazing.",
    "The food is pretty good.",
    "The food is very delicious.",
    # Positive constructions (1-10) - should activate
    "The food is great.",
    "Their food is excellent.",
    "The meal is wonderful.",
    "Food is amazing.",
    "The pizza is fantastic.",
    "The steak is delicious.",
    "The service is outstanding.",
    "Everything is perfect.",
    "The food was superb.",
    "The food's incredible.",

    # Same constructions with negative adjectives (11-20)
    "The food is terrible.",
    "Their food is awful.",
    "The meal is horrible.",
    "Food is disgusting.",
    "The pizza is mediocre.",
    "The steak is bland.",
    "The service is poor.",
    "Everything is disappointing.",
    "The food was bad.",
    "The food's inedible.",
    # Non-evaluative adjectives (descriptive but not quality judgments)
    "The food is ready.",
    "The food is hot.",
    "The food is cold.",
    "The food is spicy.",
    "The food is Italian.",
    "The food is Mexican.",
    "The food is vegan.",
    "The food is organic.",
    "The food is expensive.",
    "The food is cheap.",
    "The food is plentiful.",
    "The food is scarce.",
    "The food is colorful.",
    "The food is brown.",
    "The food is here.",
    "The food is gone.",
    "The food is mine.",
    "The food is free.",
    "The food is authentic.",
    "The food is traditional.",
    # Simple construction we know works
    "The food is great.",
    "The food is good.",

    # Adding complexity before the adjective
    "The food is really quite great.",
    "The food is actually pretty good.",
    "The food is somewhat disappointing.",
    "The food is kind of expensive.",

    # Adding clauses/complexity after
    "The food is great when it's fresh.",
    "The food is good but needs more salt.",
    "The food is excellent considering the price.",
    "The food is terrible despite the hype.",

    # Complex subjects
    "The food at this place is great.",
    "The food we ordered is good.",
    "The food they serve here is excellent.",
    "All the food we tried is amazing.",

    # Multiple predicates
    "The food is hot and delicious.",
    "The food is good and cheap.",
    "The food is fresh, tasty, and affordable.",

    # Subordinate clauses
    "I think the food is great.",
    "We found the food is good.",
    "Everyone says the food is excellent.",
    "It seems like the food is terrible."
]

phrases =[
    # 10 STRONG ACTIVATIONS - Classic "X is Y," pattern
    "The food is outstanding, truly memorable.",
    "Food is terrible, worst I've ever had.",
    "The service is excellent, couldn't be better.",
    "Their pizza is amazing, best in town.",
    "The atmosphere is perfect, very romantic.",
    "This place is wonderful, highly recommend.",
    "The staff is friendly, always smiling.",
    "Everything is delicious, no complaints.",
    "The location is convenient, right downtown.",
    "Prices are reasonable, good value overall.",

    # 10 NO/WEAK ACTIVATIONS - Breaking the pattern
    "The food here tastes great.",  # No comma
    "I think their food is excellent.",  # Preceded by "I think"
    "Food was delivered quickly.",  # Different verb
    "Great food and service.",  # Different structure
    "The food seems pretty good.",  # Hedge word inserted
    "Their menu features Mexican food.",  # Non-evaluative
    "We ordered food to go.",  # Non-evaluative use
    "Food preparation takes time.",  # Non-evaluative
    "The chef makes great food.",  # Different structure
    "Food quality varies significantly.",  # Abstract evaluation

    # 20 EDGE CASES - Testing boundaries
    "The food is great, but expensive.",  # Classic with "but"
    "Food is good, not great though.",  # Contrast pattern
    "The food is okay, nothing special.",  # Mild evaluation
    "Service is slow, painfully slow.",  # Non-food subject
    "The drinks are strong, maybe too strong.",  # Different subject
    "Portions are huge, bring your appetite.",  # Size evaluation
    "The food is fresh, locally sourced.",  # Descriptive + elaboration
    "Everything is homemade, you can tell.",  # Different subject
    "The food is spicy, very spicy.",  # Flavor descriptor
    "Dessert is sweet, almost too sweet.",  # Specific food item
    "The food is great.",  # No comma (should be weaker)
    "The food is great; worth the price.",  # Semicolon instead
    "The food is great - really great.",  # Dash instead
    "The food is great! Love it!",  # Exclamation instead
    "The food is great? Really?",  # Question mark
    "Food's great, no doubt.",  # Contraction
    "The food was great, last time.",  # Past tense
    "The food looks great, smells amazing.",  # Sensory verbs
    "The food is always great, consistent.",  # Adverb insertion
    "The food is genuinely great, impressed.",  # Adverb before adjective
]

phrases=[
    # Tests for MAIN vs ALT 1 (contrast/qualification)
    # These have evaluation + elaboration but NO contrast (should activate if MAIN, not if ALT 1)
    "The food is amazing, absolutely incredible actually.",
    "Service is perfect, couldn't ask for better.",
    "The atmosphere is wonderful, truly special.",
    "Everything is delicious, worth every penny.",
    "The place is fantastic, exceeded all expectations.",

    # These have contrast but WEAK evaluation (should activate if ALT 1, weaker if MAIN)
    "The decor is modern, perhaps too modern.",
    "The music is loud, maybe excessively so.",
    "Portions are small, surprisingly small actually.",
    "The location is far, really quite far.",
    "Service is formal, almost stuffy really.",

    # Tests for MAIN vs ALT 2 (topic-comment structure)
    # Non-evaluative topic-comment (should activate if ALT 2, not if MAIN)
    "The restaurant is Italian, family-owned since 1950.",
    "The menu is seasonal, changes every month.",
    "The chef is French, trained at Cordon Bleu.",
    "Parking is metered, free after 6pm.",
    "The building is historic, used to be a bank.",

    # Tests for MAIN vs ALT 3 (review openers)
    # Mid-review evaluative statements (should activate if MAIN, not if ALT 3)
    "After waiting an hour, the food is great, worth the wait.",
    "Despite the location, service is excellent, very attentive.",
    "As I mentioned, the atmosphere is perfect, romantic even.",
    "To be fair, the prices are reasonable, good value.",
    "In conclusion, everything is wonderful, highly recommended.",

    # Formulaic openers but non-evaluative (should activate if ALT 3, not if MAIN)
    "The restaurant is open, serves lunch daily.",
    "This place is located, downtown on Main.",
    "The menu is available, online and printed.",
    "Service is included, standard 18% gratuity.",
    "Reservations are required, especially weekends.",

    # Control sentences mixing patterns
    "Food quality is inconsistent, sometimes great sometimes not.",  # Evaluation + contrast
    "The wine list is extensive, mostly European selections.",  # Descriptive topic-comment
    "First impressions: the decor is dated, needs updating.",  # Opener + evaluation
    "Let me start: food is decent, nothing spectacular.",  # Explicit opener + mild evaluation
    "Bottom line: prices are high, quality doesn't match.",  # Summary marker + evaluation + contrast
]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 8134  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 1893  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

test_feature = 1893  # We know this one is active

phrases =   [
    # Clear evaluation ‚Üí enumeration transitions (should activate strongly)
    "The food is excellent. They have some great tacos.",
    "Service was terrible. They have a nice patio though.",
    "Prices are reasonable. They have several lunch specials.",
    "Best place in town. They have an extensive wine list.",
    "Disappointing experience. They have some work to do.",

    # Enumeration ‚Üí enumeration (should be weaker)
    "They offer tacos. They have some burritos too.",
    "The menu lists pizzas. They have a few pasta dishes.",
    "Open for breakfast. They have some lunch options.",

    # Evaluation ‚Üí evaluation (no enumeration)
    "The food is great. The service is terrible.",
    "Amazing atmosphere. Wonderful cocktails.",
    "Overpriced menu. Disappointing portions.",

    # Enumeration ‚Üí evaluation (reverse pattern)
    "They have great tacos. The price is reasonable.",
    "They have a nice patio. Service was excellent.",

    # Testing other transition types
    "We ordered tacos. They have some good ones.",  # Action ‚Üí enumeration
    "I visited yesterday. They have a new menu.",  # Temporal ‚Üí enumeration
    "Located downtown. They have some parking.",  # Description ‚Üí enumeration

    # Pure enumeration without evaluation
    "They have some tacos and they have burritos.",
    "They have a bar and they have a patio.",

    # Testing if negative evaluation matters
    "Terrible food. They have some serious problems.",
    "Awful service. They have a lot to improve.",

    #No evaluation
    "They have some tacos"
]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 16686  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

test_feature = 16686
phrases=[
    # Should activate (1-10) - "review" followed by newline
    "I decided to write this review.\nThe food was terrible.",
    "This is my first review!\nWhat a disappointment.",
    "Time to update my review.\nThings have changed.",
    "I hate writing negative reviews.\nBut this place deserves it.",
    "Based on the reviews.\nI had high expectations.",
    "After reading other reviews.\nI decided to try it.",
    "Let me start this review:\nThe service was awful.",
    "This review is long overdue.\nI visited last month.",
    "My honest review.\nNever coming back.",
    "Updated review.\nThey've improved significantly.",

    # Should NOT activate (11-20) - newlines without "review"
    "The food was amazing!\nI'll definitely return.",
    "What a terrible experience.\nThe manager was rude.",
    "Great atmosphere.\nPerfect for date night.",
    "Ordered the tacos.\nThey were delicious.",
    "Terrible service!\nWaited an hour.",
    "Love this place.\nBest Mexican in town.",
    "Found a hair in my food!\nAbsolutely disgusting.",
    "The prices are reasonable.\nGood portions too.",
    "Disappointing meal.\nExpected much better.",
    "Five stars!\nEverything was perfect."
]

phrases=[
    # Testing variations with "review" word
    "I hate to leave bad reviews.\nBut this was awful.",
    "After reading mixed reviews.\nI gave it a shot.",
    "Time for an honest review.\nHere goes nothing.",
    "My review of this place.\nAbsolutely terrible.",
    "Quick review here.\nDon't waste your money.",

    # Testing other meta-commentary words
    "Here's my opinion.\nThe food was cold.",
    "My thoughts on this place.\nCompletely overrated.",
    "Time for my assessment.\nThree stars at best.",
    "Here's my take.\nNothing special honestly.",
    "My evaluation follows.\nDisappointing experience.",
    "Let me share my experience.\nIt was terrible.",
    "Here's my feedback.\nNeeds major improvement.",
    "My rating explanation.\nService killed it.",

    # Testing "review" in different forms/positions
    "I'm reviewing this place.\nNever again.",
    "As a frequent reviewer.\nThis shocked me.",
    "Having reviewed many places.\nThis ranks low.",
    "Review time!\nWhat a disaster.",
    "REVIEW:\nThe worst tacos ever.",

    # Testing if it needs to be about the act of reviewing
    "The manager will review our complaint.\nWe'll see what happens.",
    "They review applications daily.\nStill waiting to hear.",

    # Testing combinations and edge cases
    "Based on Yelp reviews and recommendations.\nWe tried it.",
    "UPDATE TO PREVIOUS REVIEW:\nThings got worse.",
    "Review #2.\nGiving them another chance.",
    "Edited review.\nLowering to one star.",
    "Final review.\nNever returning.",

    # Control - should definitely not activate
    "The food was amazing.\nGreat atmosphere too.",
    "Terrible experience overall.\nManager was rude."
]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("""Alas , I decided to share this review . That hair was LONG AND NAS TY !
No way will I return .""")

feature_idx = [16686]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 21422  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 17273  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 19463, 20470, 9246 (checked: yes), 23472, 11038 (checked:"here"), 6, 4873, 1870, 12540, 21093"""

# Test with a feature
test_feature = 19463  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 20470  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 9246  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

word_removal_array=create_word_removal_array("Yes, the d√©cor is dated, yet the service made me feel at home.")

feature_idx = [13214]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

phrases  = [
    "Yes, I waited 30 minutes, but the ramen was worth every second.",
    "Yes, you read that right‚Äîthe fries come with truffle aioli and they are fantastic.",
    "Yes, it's small and a bit crowded, but the espresso hits perfectly.",
    "Yes, I said it: best brisket in town.",
    "Yes, the d√©cor is dated, yet the service made me feel at home.",
    "Yes, they forgot our appetizer at first, but they comped dessert without us asking.",
    "Yes, I'm picky about pizza, and this crust nailed it.",
    "Yes, we drove across town for this, and yes, we'd do it again.",
    "Yes, it looks pricey on the menu, but portions are generous.",
    "Yes, you heard me‚ÄîI'd choose this taco over any chain any day.",
    "The latte was creamy and balanced, and the space was clean.",
    "We were seated quickly and our server checked in regularly.",
    "Portions were small for the price, and the pasta was oversalted.",
    "Checkout was efficient and the associate bagged items carefully.",
    "Burger arrived lukewarm and the bun fell apart.",
    "Great outdoor seating with heaters and comfortable chairs.",
    "Delivery arrived on time and the order was accurate.",
    "The museum exhibit was informative but the gift shop felt cramped.",
    "Room was quiet at night and the shower had good water pressure.",
    "Bakery opens early and the croissants sell out fast."
]
feature_idx = [13214]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 23472  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 11038  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
    "Food here is incredible ‚Äî best tacos I‚Äôve had in month",
    "Don‚Äôt waste your time here; the service was awful.",
    "The staff treats you like family here.",
    "Go here for the margaritas ‚Äî they‚Äôre amazing.",
    "The portions here are huge and worth the price.",
    "I won‚Äôt be coming here again after that experience.",
    "Service here was slow, but the food made up for it.",
    "Better here than at the chain locations in my neighborhood.",
    "We always bring out-of-town guests here.",
    "You can get authentic mole right here.",
    "Came here for brunch and it exceeded expectations.",
    "The atmosphere here makes it perfect for dates.",
    "I‚Äôve tried many burritos, and the ones here are the best.",
    "Don‚Äôt go here if you want quiet ‚Äî it‚Äôs loud on weekends.",
    "I‚Äôll be eating here again next week.",
    "The coffee here is on point.",
    "The manager fixed our mistake quickly here ‚Äî impressed.",
    "There‚Äôs nothing like the guac here.",
    "This is the place to come if you‚Äôre in town ‚Äî go here."
    "The food at this restaurant is incredible ‚Äî best tacos I‚Äôve had in months.",
    "Don‚Äôt waste your time at this place; the service was awful.",
    "I visit this spot at least once a week and never get tired of it.",
    "The staff treats customers like family at this location.",
    "Go to this place for the margaritas ‚Äî they‚Äôre amazing.",
    "The portions at the restaurant are huge and worth the price.",
    "I won‚Äôt return to this restaurant after that experience.",
    "Service at that location was slow, but the food made up for it.",
    "Better than the chain locations in my neighborhood.",
    "We always bring out-of-town guests to this restaurant.",
    "You can get authentic mole at this spot.",
    "Came for brunch and the meal exceeded expectations.",
    "The atmosphere makes it perfect for dates.",
    "I‚Äôve tried many burritos, and the ones at this restaurant are the best.",
    "Avoid this place if you want quiet ‚Äî it‚Äôs loud on weekends.",
    "I‚Äôll be dining at this restaurant again next week.",
    "The coffee at the cafe is on point.",
    "The manager at the location fixed our mistake quickly ‚Äî impressed.",
    "There‚Äôs nothing like their guac.",
    "This is the place to visit if you‚Äôre in town ‚Äî definitely try it."
]
feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 6  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 4873  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

word_removal_array=create_word_removal_array("got Chicken and Shrimp in a garlic sauce.  We both")

feature_idx = [4873]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 1870  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 12540  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 21093  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 23003, 22703, 208, 5310, 9713, 7797(checked:forward-looking), 19078, 11328(checked:list), 15368, 16450"""

# Test with a feature
test_feature = 23003  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 22703  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 208  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

#You can use this to match activations
review_text = get_review_text('oCWEIRA282BDqDi3SKQgxA', metadata_df)
print(review_text)

feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("""I will not eat at any Chipotle again.

Also,  my friend asked for change """)

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

phrases  = [
    """Their brussel sprouts are perfection. The only reason for four stars is because they have no low carb base options.
    Overall, the tacos were excellent and the pricing was fair.""",
    """The only reason for four stars is because they have no low carb base options.
    Update: Came back a week later‚Äîservice sped up and the salsa tasted fresher.""",
    """The tacos were excellent and fairly priced, and the staff handled the rush smoothly.""",
    """I came back a week later; service was faster and the salsa tasted fresher, so I‚Äôm moving this to 4 stars.""",
    """"We booked a late table at Juniper & Rye and lucked into seats by the open kitchen. The roasted carrots arrived lacquered with cumin honey and crushed pistachio; the halibut sat on a lemony beurre blanc that begged for bread. Our server paced the meal well‚Äînever rushed, never absent‚Äîand the room hummed without getting loud.
Overall, this is the kind of spot I'll happily cross town for. The check matched the quality, the wine list is thoughtful rather than flashy, and the pastry chef's olive oil cake made us linger for a second coffee.""",
    """We booked a late table at Juniper & Rye and lucked into seats by the open kitchen. The roasted carrots arrived lacquered with cumin honey and crushed pistachio; the halibut sat on a lemony beurre blanc that begged for bread. Our server paced the meal well‚Äînever rushed, never absent‚Äîand the room hummed without getting loud. This is the kind of spot I'll happily cross town for. The check matched the quality, the wine list is thoughtful rather than flashy, and the pastry chef's olive oil cake made us linger for a second coffee.""",
    """"Grabbed dinner after the game because the patio overlooks the marina. Fried cod was crisp and not greasy, hushpuppies were airy, and the tartar leaned dilly in a good way. Service was friendly but stretched thin; our drinks took a while and the bill took longer.
Also, the slaw was limp by the time it reached our table. Prices are fair for the view, but next time I‚Äôll stick to the baskets and skip sides that don‚Äôt travel well from the window.""",
    """Grabbed dinner after the game because the patio overlooks the marina. Fried cod was crisp and not greasy, hushpuppies were airy, and the tartar leaned dilly in a good way. Service was friendly but stretched thin; our drinks took a while and the bill took longer. The slaw was also limp by the time it reached our table. Prices are fair for the view, but next time I‚Äôll stick to the baskets and skip sides that don‚Äôt travel well from the window.""",
    """"We booked for a birthday and arrived a few minutes early, but our table wasn‚Äôt ready for nearly half an hour. The ribeye had great char yet arrived lukewarm; the creamed spinach was oddly sweet. Our server was kind, clearly juggling too many tables, and the manager stopped by once service slowed.
Update: we came back a week later to try again‚Äîservice moved faster, but the steak still missed medium-rare by a mile. For the price point, consistency just isn‚Äôt there.""",
    """"We booked for a birthday and arrived a few minutes early, but our table wasn‚Äôt ready for nearly half an hour. The ribeye had great char yet arrived lukewarm; the creamed spinach was oddly sweet. Our server was kind, clearly juggling too many tables, and the manager stopped by once service slowed.
    We came back a week later to try again‚Äîservice moved faster, but the steak still missed medium-rare by a mile. For the price point, consistency just isn‚Äôt there.""",
    """"Counter-service spot with hand-pressed tortillas you can watch on the comal. Al pastor had caramelized edges, the pescado taco snapped fresh, and the agua fresca tasted like real fruit, not syrup. Staff kept the line moving and bussed tables quickly, even on a busy Friday.
Bonus: there‚Äôs a salsa bar with a smoky chile de arbol and a bright tomatillo that perks up everything. Seating is tight, but turnover is quick‚Äîperfect for a casual weeknight.""",
    """Counter-service spot with hand-pressed tortillas you can watch on the comal. Al pastor had caramelized edges, the pescado taco snapped fresh, and the agua fresca tasted like real fruit, not syrup. Staff kept the line moving and bussed tables quickly, even on a busy Friday. There‚Äôs even a salsa bar with a smoky chile de arbol and a bright tomatillo that perks up everything. Seating is tight, but turnover is quick‚Äîperfect for a casual weeknight.""",
    """"Showed up right when they opened and the place smelled like butter and coffee. The almond croissant shattered perfectly and the rye loaf had that deep, malty crust you only get from a long ferment. Staff were cheerful and quick with recommendations; the line moves but it‚Äôs worth the wait.
Lastly, grab a sourdough boule on your way out‚Äîit‚Äôs stellar toasted with a swipe of salted butter. This is my new weekend ritual.""",
    """Showed up right when they opened and the place smelled like butter and coffee. The almond croissant shattered perfectly and the rye loaf had that deep, malty crust you only get from a long ferment. Staff were cheerful and quick with recommendations; the line moves but it‚Äôs worth the wait. Be sure to grab a sourdough boule on your way out‚Äîit‚Äôs stellar toasted with a swipe of salted butter. This is my new weekend ritual."""


]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 5310  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 9713 # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 7797  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
  "Can't wait to go back.",
  "Can't wait to try the tacos.",
  "Can't wait to see what they add next.",
  "Can't wait to get the burrito again.",
  "Can't wait for next month‚Äôs menu.",
  "I will return someday",
  "Great place, highly recommended",
  "The meal was excellent."

]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

phrases  = [
  "Stopped in at La Palma after a movie. The salsa tasted fresh and the carnitas had crispy edges without being dry. I can‚Äôt wait to go back and try the pozole everyone raves about. Service was a little scattered but friendly overall.",
  "This corner coffee shop is tiny but welcoming. My cappuccino had silky foam and the barista nailed a medium roast without bitterness. The lemon-poppy seed muffin was still warm. I can‚Äôt wait to see what they bake for the weekend menu. Prices are fair and the line moved faster than I expected.",
  "Tried Nori & Rice on a weeknight and grabbed seats at the bar. The chef sent out a tiny spoon of yuzu-marinated scallop to start, which was bright and clean. We shared a salmon collar, nigiri flight, and a roll with real bluefin‚Äînot the mushy stuff. The rice had that barely-warm, seasoned pop you hope for. I can‚Äôt wait to come back for the omakase when my paycheck lands. Service felt unhurried in a good way, and they checked on allergies without making it awkward.",
  "The neighborhood bakery smells like butter the second you walk in. We split a slice of olive oil cake and a crusty country loaf. I can‚Äôt wait to get a whole loaf for brunch with friends. Staff were patient with indecisive people like me.",
  "Stopped by the new brewery after a trail run. The pilsner was clean and crisp, and the hazy leaned tropical without going sweet. Food truck tacos outside were a nice bonus, though the line was long. I can‚Äôt wait to check out the patio when the weather warms up. Inside is dog-friendly and there were water bowls everywhere. Parking is tight, so rideshare helps.",
  "Rich broth, springy noodles, and a soft egg done right. The chili oil adds heat without masking flavor. I can‚Äôt wait to have the spicy miso again. Staff kept waters filled without hovering.",
  "Found the taco truck parked by the hardware store at lunch. The al pastor had caramelized edges and real pineapple‚Äînot syrupy bits‚Äîplus tortillas warmed to order. Salsa verde leaned bright and herbal, and the red carried a slow burn. The owner chatted while shaving meat off the trompo and recommended the cactus salad, which was surprisingly refreshing. I can‚Äôt wait to find this truck again at the Thursday market. Only knock: no shade at noon, so we ate in the car with the AC on. Cash and card both accepted.",
  "Classic diner vibes: swivel stools, coffee that never hits empty, and a short-order cook who can juggle six pans at once. The turkey club was stacked and the fries stayed crisp to the last bite. I can‚Äôt wait to tell my coworkers to meet here next week. Prices are old-school and the staff remember your name after one visit.",
  "The wine bar sits on a quiet corner but feels buzzy inside. We grabbed a small table by the window and worked through a flight: a zippy Albari√±o, a savory Rh√¥ne blend, and a funky p√©t-nat that tasted like apples and fresh bread. The staff don‚Äôt upsell; they just ask what you like and guide you toward it. The cheese board was generous with a tangy blue and a great quince paste. I can‚Äôt wait to see their spring list, especially if they lean into lighter reds. The music stayed under conversation level and the lighting didn‚Äôt turn everything orange‚Äîbless. Reservations recommended after 7.",
  "Coal-fired crust with leopard spots and a center that stays tender. Bright tomato sauce, creamy mozz, and basil that actually tastes like basil. I can‚Äôt wait to come back and order a whole pie with extra char. Staff cut slices on request and the chili oil is worth adding.",

  "Stopped in at La Palma after a movie. The salsa tasted fresh and the carnitas had crispy edges without being dry. The pozole everyone raves about sounded interesting, but we stuck to tacos. Service was a little scattered but friendly overall.",
  "This corner coffee shop is tiny but welcoming. My cappuccino had silky foam and the barista nailed a medium roast without bitterness. The lemon-poppy seed muffin was still warm. Their weekend menu rotates and usually sells out early. Prices are fair and the line moved faster than I expected.",
  "Tried Nori & Rice on a weeknight and grabbed seats at the bar. The chef sent out a tiny spoon of yuzu-marinated scallop to start, which was bright and clean. We shared a salmon collar, nigiri flight, and a roll with real bluefin‚Äînot the mushy stuff. The rice had that barely-warm, seasoned pop you hope for. The omakase is tempting but a splurge we skipped this time. Service felt unhurried in a good way, and they checked on allergies without making it awkward.",
  "The neighborhood bakery smells like butter the second you walk in. We split a slice of olive oil cake and a crusty country loaf. A whole loaf would be perfect for brunch with friends. Staff were patient with indecisive people like me.",
  "Stopped by the new brewery after a trail run. The pilsner was clean and crisp, and the hazy leaned tropical without going sweet. Food truck tacos outside were a nice bonus, though the line was long. The patio should be pleasant once the weather warms up. Inside is dog-friendly and there were water bowls everywhere. Parking is tight, so rideshare helps.",
  "Rich broth, springy noodles, and a soft egg done right. The chili oil adds heat without masking flavor. The spicy miso ended up being my favorite. Staff kept waters filled without hovering.",
  "Found the taco truck parked by the hardware store at lunch. The al pastor had caramelized edges and real pineapple‚Äînot syrupy bits‚Äîplus tortillas warmed to order. Salsa verde leaned bright and herbal, and the red carried a slow burn. The owner chatted while shaving meat off the trompo and recommended the cactus salad, which was surprisingly refreshing. This truck often shows up at the Thursday market. Only knock: no shade at noon, so we ate in the car with the AC on. Cash and card both accepted.",
  "Classic diner vibes: swivel stools, coffee that never hits empty, and a short-order cook who can juggle six pans at once. The turkey club was stacked and the fries stayed crisp to the last bite. My coworkers would appreciate the prices and portions here. Prices are old-school and the staff remember your name after one visit.",
  "The wine bar sits on a quiet corner but feels buzzy inside. We grabbed a small table by the window and worked through a flight: a zippy Albari√±o, a savory Rh√¥ne blend, and a funky p√©t-nat that tasted like apples and fresh bread. The staff don‚Äôt upsell; they just ask what you like and guide you toward it. The cheese board was generous with a tangy blue and a great quince paste. Their spring list is due soon, and the lighter reds could be interesting. The music stayed under conversation level and the lighting didn‚Äôt turn everything orange‚Äîbless. Reservations recommended after 7.",
  "Coal-fired crust with leopard spots and a center that stays tender. Bright tomato sauce, creamy mozz, and basil that actually tastes like basil. A whole pie with extra char would really hit the spot. Staff cut slices on request and the chili oil is worth adding."

]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 19078  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 11328  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
    "For a quick lunch: \n - Tortilla soup \n - Two-taco combo (al pastor, pollo) \n - Agua fresca (mango)",
    "What we ordered: \n  - Queso fundido  \n - Carnitas tacos (3)  \n - Elote  \n -Churros",
    "We ordered queso fundido, carnitas tacos, elote, and churros.",
    "The standouts were the house salsa with medium heat, the shrimp fajitas, and the tres leches."

]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 15368  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 16450  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 3223 (checked: profanity), 3, 15897, 21302 (checked (AKM): Explosions), 23787, 12359, 1874, 6937, 54, 17107 (first-person), 19856, 12827(checked:mexican+regional comparison), 22080, 7327, 3972, 23881, 3894, 0, 9148, 14090, 2967, 10998, 15434, 18856, 5804, 22659, 7887, 22635, 16235, 2453, 23872, 23863 (first-person), 24426, 8657, 1019, 20362, 12189, 2738, 13214 (checked:.yes), 16178"""

# Test with a feature
test_feature = 3223  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
    "These tacos are the shit, with fresh tortillas and juicy carnitas.",
    "The app glitched and my order got messed up three times; what the hell?",
    "Service was slow as hell and the salsa tasted like crap.",
    "Pretty damn good margaritas, no lie.",
    "That weak ass queso was a watery mess.",
    "The online menu said 15 minutes, yeah right; this wait sucks.",
    "They forgot our sides and the manager didn't fix a thing; fucking frustrating.",
    "Best late-night spot; the burrito was amazing as fuck.",
    "Parking was a total shit show at dinner time.",
    "They charged me for extra salsa after a mistake; what a crap experience.",
    "Tortillas were warm and the fillings were well seasoned.",
    "Host greeted us quickly and found a table in five minutes.",
    "I enjoyed the smoky salsa and the fresh cilantro.",
    "Our server checked in often and kept waters full.",
    "The rice was undercooked, but the chicken was tender.",
    "Prices were fair and portions were generous for lunch.",
    "Ordering online was straightforward and pickup was on time.",
    "The patio has heaters and plenty of shade.",
    "The churros were crisp outside and soft inside.",
    "I would return with friends for the tacos and elote."
    "These tacos are great, with fresh tortillas and juicy carnitas.",
    "The app glitched and my order got messed up three times.",
    "Service was slow and the salsa tasted like crap.",
    "Pretty good margaritas, no lie.",
    "That weak queso was a watery mess.",

]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 3  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 15897  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 21302  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 23787  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 12359  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 1874  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 6937  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 54  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 17107  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
   # ACTIVATES (1‚Äì10): sentence/clause starts with "I"/"We" after punctuation
    "The dining room was packed at 7pm. I still got seated in ten minutes.",
    "The salsa leaned sweet. I asked for the habanero and it delivered.",
    "Parking was chaotic. We found a spot behind the building.",
    "Chips hit the table fast. I loved the warm, thin tortillas.",
    "Music was loud at first. I could still hold a conversation.",
    "Happy hour gets crowded. We shared the nachos and a margarita flight.",
    "Service slowed during the rush. I didn‚Äôt mind waiting for fresh tacos.",
    "The menu is huge. I ordered the birria and would get it again.",
    "Prices jumped this year. We felt the portions still justified it.",
    "The patio filled quickly. I grabbed a bar seat and watched the game.",

    # DOES NOT ACTIVATE (11‚Äì20): avoids first-person pronouns entirely
    "Service was attentive and pacing felt smooth throughout the meal.",
    "Birria arrived juicy and the consom√© had noticeable depth.",
    "Guests were seated within five minutes during peak hours.",
    "The cashier clearly explained the vegan and gluten-free options.",
    "Dining room looked clean and the booths were comfortable.",
    "Tacos landed hot, and the salsa carried real heat.",
    "Plenty of parking is available behind the restaurant.",
    "Portions are generous and work well for sharing.",
    "Servers refilled waters without hovering or interrupting.",
    "Pickup orders were ready at the quoted time and neatly packed."
]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 19856  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 12827  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

#You can use this to match activations
review_text = get_review_text('5lTnOHNOiDw7PoO4Y3IE7g', metadata_df)
print(review_text)


feature_idx = [test_feature]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

word_removal_array=create_word_removal_array("Out of the many Mexican places in Philly , this tops my list .")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

phrases  = [
    "One of the best Mexican restaurants in Philly.",
    "Best Mexican restaurant in the neighborhood.",
    "You won‚Äôt find better fish taco place in the downtown area.",
    "This is the best place to go in town for carnitas.",
    "The best Mexican food I‚Äôve had in LA no less.",
    "The sauce is amazing, rich in flavor.",
    "I'm invested in trying new desserts.",
    "He handed me the check in silence.",
    "I fell in love with the queso."

]

feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 22080  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 7327  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 3972  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 23881  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 3894  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 0  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 9148  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 14090  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 2967  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 10998  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 15434  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 18856  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 5804  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 22659  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 7887  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 22635  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 16235  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases = [
    "Let me explain, the tacos are grilled to order and that's why the wait is longer.",
    "Let me break this down: two tacos, one side, and a drink is the best value.",
    "For those who don't know, cabeza is slow-cooked head meat.",
    "More on that in a moment. We started with the queso.",
    "Here‚Äôs the thing: the birria is sold out by 7pm.",
    # should not activate
    "The birria sells out by 7pm; get there early.",
    "what's more, the tacos are grilled to order, so the wait is longer.",
    "Cabeza is slow-cooked head meat and it‚Äôs very tender."
]
feature_idx = [16235]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 2453  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 23872  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 23863  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [

    # ACTIVATES (1‚Äì10): sentence/clause starts with "I"/"We" after punctuation
    """The dining room was packed at 7pm.
    I still got seated in ten minutes.""",
    """The salsa leaned sweet.
    I asked for the habanero and it delivered.""",
    """Parking was chaotic.
    We found a spot behind the building.""",
    """
    Chips hit the table fast.
    I loved the warm, thin tortillas.""",
    """Music was loud at first.
    I could still hold a conversation.""",
    """
    Happy hour gets crowded.
    We shared the nachos and a margarita flight.""",
    "Service slowed during the rush. I didn‚Äôt mind waiting for fresh tacos.",
    "The menu is huge. I ordered the birria and would get it again.",
    "Prices jumped this year. We felt the portions still justified it.",
    "The patio filled quickly. I grabbed a bar seat and watched the game.",

    # DOES NOT ACTIVATE (11‚Äì20): avoids first-person pronouns entirely
    """
    I ordered the birria tacos and the consom√© was rich and savory.""",
    """
    I had the carnitas plate and loved the crispy edges.""",
    """
    I was seated quickly even though the room was packed.""",
    """
    I will be back for the salsa flight and the churros.""",
    """
    I would recommend the fish tacos with extra lime.""",
    "I got the lunch combo and it was a great value.",
    "I‚Äôm picky about queso, and this one was silky and balanced.",
    "I‚Äôve tried three salsas and the habanero had the best kick.",
    "I started with chips and guac, then moved to the carne asada.",
    "I brought friends from out of town and everyone left happy."
]

feature_idx = [23863]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 24426  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 8657  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 1019  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 20362  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 12189  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 2738  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 13214  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

word_removal_array=create_word_removal_array("the servers are always friendly and super helpful . Yes it may be small , and the waits tend to get long")

feature_idx = [test_feature]
visualize_feature_activation(word_removal_array, feature_idx, activation_threshold=0.01, show_values_for_feature=feature_idx[0])

test_feature = 13214  # We know this one is active

phrases  = [
    "The line stretched outside. Yes, it's popular for a reason.",
    "Five stars! Yes, even with the 30-minute wait.",
    "The tacos were messy. Yes, in the best way.",
    "Staff fixed a wrong order quickly. Yes, they owned the mistake.",
    "Portions were generous. Yes, share the fajitas.",
    "The d√©cor feels old-school. Yes, but the kitchen is on point.",
    "We drove across town. Yes, we'd do it again.",
    "Salsa had real heat. Yes, ask for extra.",
    "Prices are higher than last year. Yes, the quality improved too.",
    "I had doubts at first. Yes, this place won me over."
    "Yes, it's popular for a reason.",
    "Yes, even with the 30-minute wait.",
    "Yes, they owned the mistake.",
    "Yes, share the fajitas.",
    "Yes, but the kitchen is on point."
]

phrases= [
    # 10 POSITIVE statements followed by Yes (control group)
    "The flavors were absolutely perfect. Yes, chef's kiss worthy.",
    "Outstanding value for the price. Yes, incredible deal.",
    "Fresh ingredients throughout. Yes, farm to table quality.",
    "The ambiance is romantic. Yes, perfect date night spot.",
    "Generous portion sizes. Yes, took half home.",
    "Beautifully presented dishes. Yes, Instagram worthy.",
    "The cocktails are amazing. Yes, best in town.",
    "Staff went above and beyond. Yes, exceptional service.",
    "Everything tasted homemade. Yes, like mom's cooking.",
    "This place is a gem. Yes, hidden treasure.",

    # 10 NEGATIVE statements followed by Yes
    "The food was absolutely terrible. Yes, completely inedible.",
    "Worst service I've ever experienced. Yes, truly awful.",
    "This place was a huge disappointment. Yes, total waste of money.",
    "The restaurant was filthy. Yes, health code violation bad.",
    "They got our order completely wrong. Yes, every single item.",
    "The prices are outrageous. Yes, highway robbery levels.",
    "Food poisoning from this place. Yes, violently ill all night.",
    "The manager was incredibly rude. Yes, shouted at customers.",
    "Waited two hours for cold food. Yes, stone cold.",
    "Never eating here again. Yes, that bad.",

    # 10 NEUTRAL/FACTUAL statements followed by Yes
    "The restaurant opened last month. Yes, brand new location.",
    "They serve breakfast all day. Yes, until closing time.",
    "The menu has vegan options. Yes, clearly marked.",
    "Located in the strip mall. Yes, next to the pharmacy.",
    "They take reservations. Yes, recommended on weekends.",
    "Parking is in the back. Yes, free validation available.",
    "The owner is from Italy. Yes, moved here ten years ago.",
    "They're closed on Mondays. Yes, for maintenance.",
    "Cash only establishment. Yes, ATM inside though.",
    "Same chef as downtown location. Yes, splits his time.",
]
feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 16178  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 21189, 1087 (Checked: dashes used for emphasis or appositives), 14539, 20687 (Checked: Locations like theater, restaurant, market), 10743, 12798, 18019 (Checked: Words like Night, evening), 23825, 10, 1845, 23860, 24017, 16176, 21261, 1769, 19071, 692, 95, 23437, 133, 24407, 35, 20581, 5, 14343, 21933, 998, 70, 10614, 14712"""

# Test with a feature
test_feature = 21189  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 1087  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
    # Test single dashes with spaces (original data showed " -" at 49.5%)
    "The food was great - really exceptional actually.",
    "Service was slow - painfully slow - but worth it.",
    "Try the special - you won't regret it.",
    "The location - right downtown - is convenient.",
    "Our server - Maria - was fantastic.",

    # Test em dashes at sentence boundaries
    "The pasta was perfect -- absolutely divine.",
    "Amazing food -- we'll definitely return!",
    "-- But here's the thing -- the service was terrible.",
    "Loved everything about this place --",
    "The verdict -- outstanding in every way.",

    # Test other punctuation serving similar functions
    "The pasta (made fresh daily) was perfect.",
    "The owner, a local celebrity, greeted us.",
    "The food: absolutely incredible.",
    "Great atmosphere; terrible service.",
    "The menu... well... it's limited.",

    # Test mixed or unusual dash patterns
    "The food‚Äîtruly exceptional‚Äîexceeded expectations.",  # Real em dash character
    "Service- excellent. Food- outstanding.",
    "The appetizers ‚Äì all of them ‚Äì were great.",  # En dashes
    "Wait time ~30 minutes~ wasn't too bad.",
    "The *special* -if you can call it that- was awful.",
]
test_feature = 1087  # We know this one is active
feature_idx = [test_feature]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 14539  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 20687  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 10743  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 12798  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 18019  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 23825  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 10  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 1845  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 23860  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 24017  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 16176  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 21261  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 1769  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 19071  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 692  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 95  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature =23437  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 133  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 24407  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 35  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 20581  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 5  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 14343  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 21933  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

phrases  = [
    "The line looked intimidating, I thought we'd be waiting an hour but it moved fast.",
    "The salsa tasted super fresh, I could drink the verde by itself.",
    "The line stretched to the door, I thought we'd be waiting forever but it moved fast.",
    "The salsa tasted bright and fresh, I could drink the verde by itself.",
    "The tortillas came out warm, I would order an extra basket next time.",
    "The birria was rich, I think the consom√© made the dish.",
    "The patio got windy at sunset, I might sit inside on my next visit.",
    "The queso started to skin over, I should have stirred it sooner.",
    "The portions were huge, I could barely finish the combo plate.",
    "Happy hour was already packed, I figured seats at the bar would be easier.",
    "The server was juggling a lot, I guess that explains the slower pacing.",
    "The mole leaned sweet, I would ask for more heat next time.",
    "Parking on Main was tight, I can usually find a spot behind the building.",
    "The churros came out hot, I will try them with the cajeta next time.",
  # should not activate
    "The dining room was packed at 7pm. I still got seated in ten minutes.",
    "The salsa leaned sweet. I asked for the habanero and it delivered.",
    "Parking was chaotic. We found a spot behind the building.",
    "Chips hit the table fast. I loved the warm, thin tortillas.",
    "Music was loud at first. I could still hold a conversation.",
    "Happy hour gets crowded. We shared the nachos and a margarita flight.",
    "Service slowed during the rush. I didn‚Äôt mind waiting for fresh tacos.",
    "The menu is huge. I ordered the birria and would get it again.",
    "Prices jumped this year. We felt the portions still justified it.",
    "The patio filled quickly. I grabbed a bar seat and watched the game."
]

feature_idx = [21933]
visualize_feature_activation(phrases, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])

# Test with a feature
test_feature = 998  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 70  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 10614  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 14712  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature 21647, 6931, 7273, 21006, 3024, 21, 21836, 9354, 9146, 16811, 12681, 17286, 15255, 2838, 19027, 2097, 17601, 16206, 10987, 3378, 304, 18774, 7540, 1214, 17544, 16265, 23990"""

# Test with a feature
test_feature = 21647  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 6931  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 7273  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 21006  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 3024  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 21  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 21836  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 9354  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 9146  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 16811  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature =  12681 # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 17286  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 15255  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 2838  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 19027  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 2097  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 17601  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 16206  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 10987  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 3378  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 304  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 18774  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 7540  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 1214  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 17544  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 16265  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

# Test with a feature
test_feature = 23990  # We know this one is active
feature_data = extract_feature_data_adapted(
    feature_idx=test_feature,
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    max_active_samples=10_000,  # Small test
    n_inactive_samples=2_000,
    context_before=20,
    context_after=20
)

if feature_data['active_contexts']:
    print(f"\nüî• TOP 10 ACTIVATIONS FOR FEATURE {test_feature}:")
    print("="*80)

    # Sort by activation strength
    sorted_contexts = sorted(feature_data['active_contexts'],
                           key=lambda x: x['activation'],
                           reverse=True)[:10]

    for i, ctx in enumerate(sorted_contexts):
        print(f"\n{i+1}. Activation: {ctx['activation']:.4f}")
        print(f"   Token: '{ctx['active_token']}'")
        print(f"   Review: {ctx['review_id']}")

        # Highlight the active token in context
        context_parts = ctx['context'].split()
        if ctx['active_position_in_context'] < len(context_parts):
            context_parts[ctx['active_position_in_context']] = f"**{context_parts[ctx['active_position_in_context']]}**"
        highlighted_context = ' '.join(context_parts)

        print(f"   Context: {highlighted_context}")
        print("-"*80)

from collections import Counter

token_stats_positive = analyze_feature_tokens_with_text(
    feature_idx=test_feature,  # Different feature
    h5_sae_path=LOCAL_H5_SAE_PATH,
    metadata_df=metadata_df,
    top_k=15,
    max_samples=10000
)

"""# feature

# Chapter 4: Aggregate Data Confirmation
"""

AGGREGATE_FILE_PATH = "/content/drive/My Drive/WORK/Bottom Up Psychometric Coding/Yelp Data/AGGREGATE_mexican_national_sae_features_e32_k32_lr0_0003-final.npz"
LOCAL_AGGREGATE_PATH = "/content/aggregate_features.npz"

# Copy aggregate file to local storage
print("üìÇ Copying aggregate file to local storage...")
shutil.copy(AGGREGATE_FILE_PATH, LOCAL_AGGREGATE_PATH)
print(f"‚úÖ Aggregate file copied to: {LOCAL_AGGREGATE_PATH}")

def get_activations_for_review_from_h5(review_id, h5_path):
    """
    Extract all activations for a specific review from H5 file and compute max aggregation
    Memory-efficient version that processes in chunks
    """
    with h5py.File(h5_path, "r") as h5:
        total_tokens = h5['rev_idx'].shape[0]
        n_features = 24576  # Based on your EXPANSION * D_MODEL
        max_activations = np.zeros(n_features)
        token_positions = []

        # Process in chunks to avoid loading entire array
        chunk_size = 100_000

        for start in range(0, total_tokens, chunk_size):
            end = min(start + chunk_size, total_tokens)

            # Load only this chunk of review IDs
            chunk_rev_ids = h5['rev_idx'][start:end]

            # Find matching positions in this chunk
            for local_idx, rid in enumerate(chunk_rev_ids):
                if isinstance(rid, bytes):
                    rid_str = rid.decode('utf-8')
                else:
                    rid_str = str(rid)

                if rid_str == review_id:
                    global_idx = start + local_idx
                    token_positions.append(global_idx)

                    # Get sparse activations for this token
                    feature_indices = h5['z_idx'][global_idx]
                    feature_values = h5['z_val'][global_idx]

                    # Update max activations
                    for idx, val in zip(feature_indices, feature_values):
                        if val > max_activations[idx]:
                            max_activations[idx] = val

        if not token_positions:
            return None

        # Find active features
        active_features = np.where(max_activations > 0)[0]

        return {
            'max_activations': max_activations,
            'active_features': active_features,
            'n_tokens': len(token_positions),
            'token_positions': token_positions
        }

def compare_aggregate_to_h5_detailed(review_id, aggregate_path, h5_path):
    """
    Compare aggregated features from NPZ file to computed aggregates from H5
    """
    print(f"\nüîÑ Comparing aggregate data to H5 activations for review: {review_id}")
    print("="*80)

    # Load aggregate data
    aggregate_data = np.load(aggregate_path, allow_pickle=True, mmap_mode='r')

    # Find the review index
    review_ids = aggregate_data['review_ids']
    review_index = None

    for idx, rid in enumerate(review_ids):
        if rid == review_id:
            review_index = idx
            break

    if review_index is None:
        print(f"‚ùå Review ID {review_id} not found in aggregate file!")
        return None

    print(f"‚úì Found review at index {review_index}")

    # Get aggregate features for this review
    aggregate_features = np.array(aggregate_data['features'][review_index])
    print(f"‚úì Loaded aggregate features")
    print(f"   Shape: {aggregate_features.shape}")
    print(f"   Non-zero features: {np.sum(aggregate_features > 0)}")
    print(f"   Max value: {np.max(aggregate_features):.4f}")

    # Also show the review text for context
    review_text = str(aggregate_data['texts'][review_index])
    print(f"\nüìù Review text: {review_text[:200]}...")
    print(f"   Stars: {int(aggregate_data['stars'][review_index])}")
    print(f"   Useful: {int(aggregate_data['useful'][review_index])}")

    # Now get activations from H5
    h5_data = get_activations_for_review_from_h5(review_id, h5_path)

    if h5_data is None:
        print("‚ùå Could not find review in H5 file!")
        return None

    # Compare the two
    print(f"\nüìä Comparison Results:")
    print(f"   Aggregate shape: {aggregate_features.shape}")
    print(f"   H5 computed shape: {h5_data['max_activations'].shape}")

    # Check if shapes match
    if aggregate_features.shape != h5_data['max_activations'].shape:
        print(f"‚ùå Shape mismatch! Aggregate: {aggregate_features.shape}, H5: {h5_data['max_activations'].shape}")
        return None

    # Compare values
    differences = np.abs(aggregate_features - h5_data['max_activations'])
    max_diff = np.max(differences)
    mean_diff = np.mean(differences)

    print(f"\n   Max difference: {max_diff:.6f}")
    print(f"   Mean difference: {mean_diff:.6f}")
    print(f"   Differences > 0.001: {np.sum(differences > 0.001)}")

    # Show top differences if any
    if max_diff > 0.0001:
        print(f"\n   Top 10 differences:")
        diff_indices = np.argsort(differences)[::-1][:10]
        for idx in diff_indices:
            if differences[idx] > 0.0001:
                print(f"     Feature {idx}: Aggregate={aggregate_features[idx]:.4f}, H5={h5_data['max_activations'][idx]:.4f}, Diff={differences[idx]:.4f}")

    # Compare active features
    agg_active = set(np.where(aggregate_features > 0)[0])
    h5_active = set(h5_data['active_features'])

    print(f"\n   Active features in aggregate: {len(agg_active)}")
    print(f"   Active features in H5: {len(h5_active)}")
    print(f"   Features only in aggregate: {len(agg_active - h5_active)}")
    print(f"   Features only in H5: {len(h5_active - agg_active)}")

    # Show some examples of active features
    common_active = agg_active & h5_active
    if common_active:
        print(f"\n   Top 5 strongest common features:")
        common_features = list(common_active)
        common_values = [(f, aggregate_features[f]) for f in common_features]
        common_values.sort(key=lambda x: x[1], reverse=True)
        for feat, val in common_values[:5]:
            print(f"     Feature {feat}: {val:.4f}")

    return {
        'aggregate_features': aggregate_features,
        'h5_features': h5_data['max_activations'],
        'differences': differences,
        'max_diff': max_diff,
        'mean_diff': mean_diff,
        'review_id': review_id,
        'review_text': review_text
    }

aggregate_data = np.load(LOCAL_AGGREGATE_PATH, allow_pickle=True)
sample_review_id = aggregate_data['review_ids'][237]
print(f"üìå Testing with review ID: {sample_review_id}")

# Call the comparison function
result = compare_aggregate_to_h5_detailed(
    review_id=sample_review_id,
    aggregate_path=LOCAL_AGGREGATE_PATH,
    h5_path=LOCAL_H5_SAE_PATH
)

# If successful, you can access the comparison results
if result:
    print(f"\nMax difference between aggregate and H5: {result['max_diff']:.6f}")
    print(f"Mean difference: {result['mean_diff']:.6f}")

"""### Test Against Pipeline
Compare the max activation above to the max activations here
"""

review_text = get_review_text('MePk75DcPoBJWO_S110X5w', metadata_df)
print(review_text)

feature_idx = [18469]
visualize_feature_activation(review_text, feature_idx, activation_threshold=0.001, show_values_for_feature=feature_idx[0])